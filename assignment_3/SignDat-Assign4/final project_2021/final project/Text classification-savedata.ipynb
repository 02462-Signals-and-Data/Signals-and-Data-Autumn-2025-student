{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Given data***  \n",
    "News articles in 4 categories  \n",
    "- 120k train\n",
    "- 7.6k test\n",
    "\n",
    "***Ideas***  \n",
    "1) Summarize news articles using Glove embeddings   (transfer learning-ish)\n",
    "2) Compute and visualize PCA  \n",
    "3) Construct and evaluate classifier of own choice  \n",
    "\n",
    "4) Use given code to train classifier based on tri-gram embeddings  \n",
    "5) Plot and visualize features  \n",
    "6) Write own small news and visualize in plot  \n",
    "7) Find nearest neighbor articles  \n",
    "8) Compare this classifier with classifier in 3)  \n",
    "9) Investigate how the embedding dimension affects the classifier and latent representation\n",
    "\n",
    "\n",
    "***Other ideas***  \n",
    "a) Try different data set? SPAM?\n",
    "b) Investigate calibration of classifier  \n",
    "c) ..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pylab as plt\n",
    "import seaborn as snb\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import text_classification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "snb.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array(['Romance', 'Thriller', 'Sci-Fi'], dtype=object)"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_data.csv')\n",
    "df.Genre.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_genre = {0 : 'Romance',\n",
    "                 1 : 'Sci-Fi',\n",
    "                 2 : 'Thriller'}\n",
    "\n",
    "movies_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0       John and Max resolve to save their beloved bai...\n1       Based on Terry McMillan's novel, this film fol...\n2       A group of professional bank robbers start to ...\n3       An ugly duckling having undergone a remarkable...\n4       Years after a friend and fellow 00 agent is ki...\n                              ...                        \n3560    With retirement on his mind, a successful Atla...\n3561    A robot created by the military falls into the...\n3562    TILT is a love story set against the backdrop ...\n3563    In an era where aliens have invaded and conque...\n3564    The silver-haired samurai Sakata Gintoki inves...\nName: Plot, Length: 3565, dtype: object"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2673,) it should be (2673, )\n",
      "(892,) it should be (892, )\n",
      "(2673,) it should be (2673, )\n",
      "(892,) it should be (892, )\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df.Plot,df.Genre)\n",
    "\n",
    "\n",
    "\n",
    "n_train_subjects = np.shape(X_train)[0]\n",
    "\n",
    "\n",
    "\n",
    "n_test_subjects = np.shape(X_test)[0]\n",
    "\n",
    "\n",
    "\n",
    "# Check that we have 25 % test:\n",
    "\n",
    "\n",
    "\n",
    "print(np.shape(X_train), \"it should be (2673, )\")\n",
    "print(np.shape(X_test), \"it should be (892, )\")\n",
    "print(np.shape(Y_train), \"it should be (2673, )\")\n",
    "print(np.shape(Y_test), \"it should be (892, )\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-49-676ea48a2ac7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m     \u001B[0mtrue_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokens\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_dataset2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_text\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_dataset2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_vocab\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_dataset2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_texts = []\n",
    "test_texts = []\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "\n",
    "def get_text(tokens, voc):\n",
    "    return  ' '.join([voc.itos[token] for token in tokens])\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(train_dataset2._data))):\n",
    "    true_label, tokens = train_dataset2._data[i]\n",
    "    text = get_text(tokens, train_dataset2.get_vocab())\n",
    "    \n",
    "    train_texts.append(text)\n",
    "    train_labels.append(true_label)\n",
    "\n",
    "for i in tqdm(range(len(test_dataset2._data))):\n",
    "    true_label, tokens = test_dataset2._data[i]\n",
    "    text = get_text(tokens, test_dataset2.get_vocab())\n",
    "\n",
    "    test_texts.append(text)\n",
    "    test_labels.append(true_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = {'train_texts': train_texts,\n",
    "             'test_texts': test_texts,\n",
    "             'train_labels': train_labels,\n",
    "             'test_labels': test_labels,\n",
    "             'ag_news_label': list(ag_news_label.values()),\n",
    "             }\n",
    "\n",
    "#np.savez('./news_data.npz', **news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train =np.array(X_train)\n",
    "X_train[7]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    j = np.random.choice(range(len(X_train)))\n",
    "    print(j)\n",
    "    print('Genre: %s' % Y_train[j])\n",
    "    print(60*'-')\n",
    "    print(X_train[j])\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Glove Embeddings (transfer learning ish?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"glove.6B.100d.txt\"\n",
    "\n",
    "dictionary = {}\n",
    "with open(filename,'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        elements = line.split();\n",
    "        word = elements[0];\n",
    "        vector = np.asarray(elements[1:],\"float32\")\n",
    "        dictionary[word] = vector;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute mean embedding for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_train = []\n",
    "feats_test = []\n",
    "\n",
    "def clean(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "for text in tqdm(train_texts):\n",
    "    words = clean(text).split()\n",
    "    feats_train.append(np.mean([dictionary[word] for word in words if word in dictionary], 0))\n",
    "    \n",
    "\n",
    "for text in tqdm(test_texts):\n",
    "    words = clean(text).split()\n",
    "    feats_test.append(np.mean([dictionary[word] for word in words if word in dictionary], 0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "feats_train = np.stack(feats_train)\n",
    "feats_test = np.stack(feats_test)\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "pca2 = PCA(n_components=4)\n",
    "Vtrain = pca2.fit_transform(feats_train)\n",
    "Vtest = pca2.fit_transform(feats_test)\n",
    "\n",
    "\n",
    "colors = 'rgbk'\n",
    "for c, Z, title in zip([train_labels, test_labels], [Vtrain, Vtest], ['Training set', 'Test set']):\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC2')\n",
    "    plt.ylabel('PC3')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC3')\n",
    "    plt.ylabel('PC4')\n",
    "    plt.suptitle(title, fontweight='bold', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Apply and evaluate classifier of own choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn\n",
    "means = []\n",
    "covs = []\n",
    "\n",
    "\n",
    "Z, c = Vtrain, train_labels\n",
    "for i in range(4):\n",
    "    means.append(np.mean(Z[c==i, :], axis=0))\n",
    "    covs.append(np.cov(Z[c==i, :].T))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logps = np.zeros((len(test_labels), 4))\n",
    "\n",
    "# assuming equal priors\n",
    "for n in tqdm(range(len(test_labels))):\n",
    "    for i in range(4):\n",
    "        logps[n, i] = mvn.logpdf(Vtest[n, :], means[i], covs[i])\n",
    "        \n",
    "pred = np.argmax(logps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test accuracy: %3.2f' % np.mean(pred == test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification using 3-gram embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class TextClassification(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, offsets):\n",
    "        embedded = self.embedding(text, offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUN_CLASS = len(train_dataset.get_labels())\n",
    "model = TextClassification(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text = [entry[1] for entry in batch]\n",
    "    offsets = [0] + [len(entry) for entry in text]\n",
    "    # torch.Tensor.cumsum returns the cumulative sum\n",
    "    # of elements in the dimension dim.\n",
    "    # torch.Tensor([1.0, 2.0, 3.0]).cumsum(dim=0)\n",
    "\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text = torch.cat(text)\n",
    "    return text, offsets, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = model(text, offsets)\n",
    "        loss = criterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(text, offsets)\n",
    "            loss = criterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "N_EPOCHS = 5\n",
    "min_valid_loss = float('inf')\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(test_dataset)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "\n",
    "def predict(text, model, vocab, ngrams, return_top=False, return_output=False):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        if return_top:\n",
    "            topv, topi = output.topk(4, 1, True)\n",
    "            topv = topv.detach().numpy()\n",
    "            topi = topi.detach().numpy()\n",
    "            return topv, topi\n",
    "        elif return_output:\n",
    "            return output\n",
    "        else:\n",
    "            return output.argmax(1).item()\n",
    "\n",
    "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
    "    enduring the season’s worst weather conditions on Sunday at The \\\n",
    "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
    "    considering the wind and the rain was a respectable showing. \\\n",
    "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
    "    was another story. With temperatures in the mid-80s and hardly any \\\n",
    "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
    "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
    "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
    "    was even more impressive considering he’d never played the \\\n",
    "    front nine at TPC Southwind.\"\n",
    "\n",
    "vocab = train_dataset.get_vocab()\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA (try both training and test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest = [], []\n",
    "ctrain, ctest = [], []\n",
    "\n",
    "data = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "for text, offsets, cls in data:\n",
    "    \n",
    "    output = model.embedding(text, offsets)\n",
    "    \n",
    "    Xtrain.append(output.detach().numpy())\n",
    "    ctrain.append(cls.detach().numpy())\n",
    "    \n",
    "\n",
    "data = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "for text, offsets, cls in data:\n",
    "    \n",
    "    output = model.embedding(text, offsets)\n",
    "    \n",
    "    Xtest.append(output.detach().numpy())\n",
    "    ctest.append(cls.detach().numpy())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.vstack(Xtrain)\n",
    "Xtest = np.vstack(Xtest)\n",
    "ctrain = np.hstack(ctrain)\n",
    "ctest = np.hstack(ctest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=32)\n",
    "\n",
    "Ztrain = pca.fit_transform(Xtrain)\n",
    "Ztest = pca.transform(Xtest)\n",
    "\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Eigenvalue index')\n",
    "plt.title('Explained variance')\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "Ztrain = pca.fit_transform(Xtrain)\n",
    "Ztest = pca.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = 'rgbk'\n",
    "for c, Z, title in zip([ctrain, ctest], [Ztrain, Ztest], ['Training set', 'Test set']):\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC2')\n",
    "    plt.ylabel('PC3')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for i in range(4):\n",
    "        plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=ag_news_label[i])\n",
    "    plt.legend()\n",
    "    plt.xlabel('PC3')\n",
    "    plt.ylabel('PC4')\n",
    "    plt.suptitle(title, fontweight='bold', fontsize=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_text = 'The team suffered a great and very surprising defeat.'# It was a crisis situation, people were losing big money.'\n",
    "my_text = 'Apple presents the newest smarthpone with more features than ever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Text: %s\\n\\n' % my_text)\n",
    "\n",
    "\n",
    "topv, topi = predict(my_text, model, vocab, 2, return_top=True)\n",
    "\n",
    "print('Rank\\tCategory\\tScore')\n",
    "print(60*'-')\n",
    "for rank in range(4):\n",
    "    print('#%d\\t%-15s (%3.2f)' % (rank+1, ag_news_label[topi[0, rank]], topv[0, rank]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Own \"news\" in the PCA plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_predict(text, model, vocab, ngrams):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor([vocab[token]\n",
    "                            for token in ngrams_iterator(tokenizer(text), ngrams)])\n",
    "        emb = model.embedding(text, torch.LongTensor([0]))\n",
    "        return emb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Z, c = Ztest, ctest\n",
    "\n",
    "my_X = my_predict(my_text, model, vocab, 2)\n",
    "my_Z = pca.transform(my_X)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 0], my_Z[0, 1], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 0], my_Z[0, 1], 'c.', label='My text', markersize=10)\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "    \n",
    "plt.subplot(1, 3, 2)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 1], my_Z[0, 2], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 1], my_Z[0, 2], 'c.', label='My text', markersize=10)\n",
    "plt.legend()\n",
    "plt.xlabel('PC2')\n",
    "plt.ylabel('PC3')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 2], my_Z[0, 3], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 2], my_Z[0, 3], 'c.', label='My text', markersize=10)\n",
    "plt.legend()\n",
    "plt.xlabel('PC3')\n",
    "plt.ylabel('PC4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "dists = [cosine(my_Z, Zi) for Zi in Z]\n",
    "\n",
    "best_idx = np.argmin(dists)\n",
    "\n",
    "voc = test_dataset2.get_vocab()\n",
    "label, tokens = test_dataset2._data[best_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('My text')\n",
    "print(50*'-')\n",
    "print(my_text)\n",
    "print('\\n\\n')\n",
    "\n",
    "\n",
    "s = get_text(tokens, test_dataset2.get_vocab())\n",
    "print('Nearest neighbor (cos. dist = %3.2f)' % dists[best_idx])\n",
    "print(50*'-')\n",
    "print(s)\n",
    "print('\\n\\n')\n",
    "print('True label: %s' % ag_news_label[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot nearest neighbor in PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 0], my_Z[0, 1], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 0], my_Z[0, 1], 'c.', label='My text', markersize=10)\n",
    "plt.plot(Z[best_idx, 0], Z[best_idx, 1], 'm.', markersize=25, label='NN')\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "    \n",
    "plt.subplot(1, 3, 2)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 1], my_Z[0, 2], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 1], my_Z[0, 2], 'c.', label='My text', markersize=10)\n",
    "plt.plot(Z[best_idx, 1], Z[best_idx, 2], 'm.', markersize=25, label='NN')\n",
    "plt.legend()\n",
    "plt.xlabel('PC2')\n",
    "plt.ylabel('PC3')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for i in range(4):\n",
    "    plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=ag_news_label[i])\n",
    "plt.plot(my_Z[0, 2], my_Z[0, 3], 'w.', markersize=25)\n",
    "plt.plot(my_Z[0, 2], my_Z[0, 3], 'c.', label='My text', markersize=10)\n",
    "plt.plot(Z[best_idx, 2], Z[best_idx, 3], 'm.', markersize=25, label='NN')\n",
    "plt.legend()\n",
    "plt.xlabel('PC3')\n",
    "plt.ylabel('PC4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "correct = []\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "for i in range(len(test_dataset2._data)):\n",
    "\n",
    "    true_label, tokens = test_dataset2._data[i]\n",
    "    text = get_text(tokens, voc)\n",
    "\n",
    "    output = predict(text, model, vocab, 2, return_output=True)\n",
    "    prob = sm(output)\n",
    "    probs.append(prob[0, true_label].item())\n",
    "    correct.append(1.0*(output.argmax(1).item() == true_label))\n",
    "\n",
    "\n",
    "\n",
    "probs = np.array(probs)\n",
    "correct = np.array(correct)\n",
    "\n",
    "pairs = list(zip(probs, correct))\n",
    "\n",
    "def in_interval(x, a, b):\n",
    "    return a <= x < b\n",
    "\n",
    "end_points = np.linspace(0, 0.95, 20)\n",
    "\n",
    "intervals = [(ep, ep+0.05) for ep in end_points]\n",
    "\n",
    "accs = []\n",
    "counts = []\n",
    "\n",
    "for a,b in intervals:\n",
    "    vals = [cor for p, cor in pairs if in_interval(p, a, b)]\n",
    "    if len(vals) > 0:\n",
    "        acc = np.mean(vals)\n",
    "    else:\n",
    "        acc = 0\n",
    "        \n",
    "    counts.append(len(vals))\n",
    "            \n",
    "    accs.append(acc)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(end_points+0.05, accs, 'r', label='Actual classifier')\n",
    "plt.plot(end_points+0.05, accs, 'r.', markersize=12)\n",
    "plt.plot(end_points+0.05, end_points+.05, 'b-', alpha=0.5, label='Ideal classifier')\n",
    "for p in end_points:\n",
    "    plt.axvline(p-0.025, color='k', linestyle='-', alpha=0.1)\n",
    "plt.xlabel('Uncertainty estimate')\n",
    "plt.ylabel('Actual uncertainty')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUick and dirty code for loading SPAM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./SMSSpamCollection', delimiter='\\t', header=None)\n",
    "\n",
    "\n",
    "spamlabel = data[0]\n",
    "spamtext = data[1]\n",
    "Nspam = len(spamlabel)\n",
    "\n",
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    #text = re.sub('[0-9]+', '$', text)\n",
    "    #text = re.sub(r\"[,.;@#?!&$]+\", ' ', text)\n",
    "    \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "    \n",
    "    \n",
    "spamtext = np.array([clean(text) for text in spamtext])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.load('./news_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['train_labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2int = {'spam': 1, 'ham': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrain = int(0.8*Nspam)\n",
    "\n",
    "spam_train_idx = np.random.choice(range(Nspam), size=Ntrain, replace=False)\n",
    "spam_test_idx = np.setdiff1d(range(Nspam), spam_train_idx)\n",
    "\n",
    "spamlabel_train = spamlabel[spam_train_idx]\n",
    "spamlabel_test = spamlabel[spam_test_idx]\n",
    "\n",
    "spamtext_train = spamtext[spam_train_idx]\n",
    "spamtext_test = spamtext[spam_test_idx]\n",
    "\n",
    "f = open('./spam_train.csv', \"w\")\n",
    "for label, text in zip(spamlabel_train, spamtext_train):\n",
    "    if label == 'spam':\n",
    "        f.write('\"%d\", \"%s\"\\n' % (1, text))\n",
    "    else:\n",
    "        f.write('\"%d\",\"%s\"\\n' % (0, text))\n",
    "f.close()\n",
    "\n",
    "f = open('./spam_test.csv', \"w\")\n",
    "for label, text in zip(spamlabel_test, spamtext_test):\n",
    "    if label == 'spam':\n",
    "        f.write('\"%d\", \"%s\"\\n' % (1, text))\n",
    "    else:\n",
    "        f.write('\"%d\", \"%s\"\\n' % (0, text))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamlabel_train_int = [lab2int[lab] for lab in spamlabel_train]\n",
    "spamlabel_test_int = [lab2int[lab] for lab in spamlabel_test]\n",
    "\n",
    "spam_data = {'train_texts': spamtext_train,\n",
    "             'test_texts': spamtext_test,\n",
    "             'train_labels': spamlabel_train_int,\n",
    "             'test_labels': spamlabel_test_int,\n",
    "             'labels': ['not-spam', 'spam'],\n",
    "             }\n",
    "\n",
    "np.savez('./spam_data.npz', **spam_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import ngrams_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.utils import download_from_url, extract_archive, unicode_csv_reader\n",
    "from torchtext.vocab import Vocab\n",
    "import io\n",
    "\n",
    "def _csv_iterator(data_path, ngrams, yield_cls=False):\n",
    "    tokenizer = get_tokenizer(\"basic_english\")\n",
    "    with io.open(data_path, encoding=\"utf8\") as f:\n",
    "        reader = unicode_csv_reader(f)\n",
    "        for row in reader:\n",
    "            tokens = ' '.join(row[1:])\n",
    "            tokens = tokenizer(tokens)\n",
    "            if yield_cls:\n",
    "                yield int(row[0]), ngrams_iterator(tokens, ngrams)\n",
    "            else:\n",
    "                yield ngrams_iterator(tokens, ngrams)\n",
    "\n",
    "\n",
    "def _create_data_from_iterator(vocab, iterator, include_unk):\n",
    "    data = []\n",
    "    labels = []\n",
    "    with tqdm(unit_scale=0, unit='lines') as t:\n",
    "        for cls, tokens in iterator:\n",
    "            if include_unk:\n",
    "                tokens = torch.tensor([vocab[token] for token in tokens])\n",
    "            else:\n",
    "                token_ids = list(filter(lambda x: x is not Vocab.UNK, [vocab[token]\n",
    "                                        for token in tokens]))\n",
    "                tokens = torch.tensor(token_ids)\n",
    "            if len(tokens) == 0:\n",
    "                logging.info('Row contains no tokens.')\n",
    "            data.append((cls, tokens))\n",
    "            labels.append(cls)\n",
    "            t.update(1)\n",
    "    return data, set(labels)\n",
    "\n",
    "\n",
    "\n",
    "def prep_spam_data(spam_vocab=None, ngrams=3, include_unk=True):\n",
    "    train_csv_path = './spam_train.csv'\n",
    "    test_csv_path = './spam_test.csv'\n",
    "\n",
    "    if spam_vocab is None:\n",
    "        spam_vocab = build_vocab_from_iterator(_csv_iterator(train_csv_path, ngrams))\n",
    "        \n",
    "    train_data, train_labels = _create_data_from_iterator(spam_vocab, _csv_iterator(train_csv_path, ngrams, yield_cls=True), include_unk)\n",
    "    test_data, test_labels = _create_data_from_iterator(spam_vocab, _csv_iterator(test_csv_path, ngrams, yield_cls=True), include_unk)\n",
    "\n",
    "    spamdata_train = torchtext.datasets.TextClassificationDataset(spam_vocab, train_data, train_labels)\n",
    "    spamdata_test = torchtext.datasets.TextClassificationDataset(spam_vocab, test_data, test_labels)\n",
    "    \n",
    "    return spamdata_train, spamdata_test \n",
    "    \n",
    "# use vocab from pretrained model\n",
    "spamdata_train, spamdata_test = prep_spam_data(spam_vocab=vocab, ngrams=3, include_unk=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map spam data through model trained on news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xspam_train = []\n",
    "cspam_train = []\n",
    "\n",
    "data = DataLoader(spamdata_train, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "for text, offsets, cls in data:\n",
    "    \n",
    "    output = model.embedding(text, offsets)\n",
    "    \n",
    "    Xspam_train.append(output.detach().numpy())\n",
    "    cspam_train.append(cls.detach().numpy())\n",
    "\n",
    "Xspam_train = np.vstack(Xspam_train)\n",
    "cspam_train = np.hstack(cspam_train)\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "Zspam_train = pca.fit_transform(Xspam_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_labels=['Ham', 'Spam']\n",
    "\n",
    "Z, c = Zspam_train, cspam_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=spam_labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "\n",
    "    \n",
    "plt.subplot(1, 3, 2)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=spam_labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('PC2')\n",
    "plt.ylabel('PC3')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=spam_labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('PC3')\n",
    "plt.ylabel('PC4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick and dirty code for training model on SPAM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use own vocab\n",
    "spamdata_train, spamdata_test = prep_spam_data(spam_vocab=None, ngrams=3, include_unk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spammodel = TextClassification(VOCAB_SIZE, EMBED_DIM, NUN_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_func(sub_train_):\n",
    "\n",
    "    # Train the model\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      collate_fn=generate_batch)\n",
    "    for i, (text, offsets, cls) in enumerate(data):\n",
    "        spamoptimizer.zero_grad()\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        output = spammodel(text, offsets)\n",
    "        loss = spamcriterion(output, cls)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        spamoptimizer.step()\n",
    "        train_acc += (output.argmax(1) == cls).sum().item()\n",
    "        \n",
    "\n",
    "    # Adjust the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)\n",
    "\n",
    "def test(data_):\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    data = DataLoader(data_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "    for text, offsets, cls in data:\n",
    "        text, offsets, cls = text.to(device), offsets.to(device), cls.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = spammodel(text, offsets)\n",
    "            loss = spamcriterion(output, cls)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == cls).sum().item()\n",
    "            \n",
    "\n",
    "    return loss / len(data_), acc / len(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spamcriterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "spamoptimizer = torch.optim.SGD(spammodel.parameters(), lr=4.0)\n",
    "spamscheduler = torch.optim.lr_scheduler.StepLR(spamoptimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(spamdata_train) * 0.95)\n",
    "sub_train_, sub_valid_ = \\\n",
    "    random_split(spamdata_train, [train_len, len(spamdata_train) - train_len])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train_func(sub_train_)\n",
    "    valid_loss, valid_acc = test(sub_valid_)\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "\n",
    "    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking the results of test dataset...')\n",
    "test_loss, test_acc = test(spamdata_test)\n",
    "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note test set accuracy seems fragile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xspam_train = []\n",
    "cspam_train = []\n",
    "\n",
    "data = DataLoader(spamdata_train, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "for text, offsets, cls in data:\n",
    "    \n",
    "    output = spammodel.embedding(text, offsets)\n",
    "    \n",
    "    Xspam_train.append(output.detach().numpy())\n",
    "    cspam_train.append(cls.detach().numpy())\n",
    "\n",
    "Xspam_train = np.vstack(Xspam_train)\n",
    "cspam_train = np.hstack(cspam_train)\n",
    "\n",
    "\n",
    "Zspam_train = pca.fit_transform(Xspam_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_labels=['Ham', 'Spam']\n",
    "\n",
    "Z, c = Zspam_train, cspam_train\n",
    "\n",
    "p = np.mean(Z[c==1,:], 0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=spam_labels[i])\n",
    "    \n",
    "plt.plot(p[0], p[1], 'c.')\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "plt.subplot(1, 3, 2)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 1], Z[c==i, 2], '.', color=colors[i], label=spam_labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('PC2')\n",
    "plt.ylabel('PC3')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 2], Z[c==i, 3], '.', color=colors[i], label=spam_labels[i])\n",
    "plt.legend()\n",
    "plt.xlabel('PC3')\n",
    "plt.ylabel('PC4')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map mean (cyan point in the plot above) back to embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = pca.inverse_transform(p)\n",
    "Xp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vocab = spamdata_train.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = []\n",
    "\n",
    "for i in range(len(spam_vocab.itos)):\n",
    "    emb = spammodel.embedding.weight[i]\n",
    "    dists.append(cosine(Xp, emb.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(dists)\n",
    "for rank in range(100):\n",
    "    j = sort_idx[rank]\n",
    "    term = spam_vocab.itos[j]\n",
    "    print('#%2d\\t%-15s (%3.2f)' % (rank+1, term, dists[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_labels=['Ham', 'Spam']\n",
    "\n",
    "Z, c = Zspam_train, cspam_train\n",
    "\n",
    "test_phrases= ['get free',  'free', 'win', 'award', 'industry', 'see you', 'why is', 'house']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(2):\n",
    "    plt.plot(Z[c==i, 0], Z[c==i, 1], '.', color=colors[i], label=spam_labels[i])\n",
    "\n",
    "for test_phrase in test_phrases:\n",
    "    p1 = pca.transform(spammodel.embedding.weight[spam_vocab.stoi[test_phrase]].detach().numpy().reshape(1, -1))\n",
    "    plt.plot(p1[0,0], p1[0,1], 'c.', markersize=15)\n",
    "    plt.text(p1[0,0], p1[0,1], test_phrase)\n",
    "plt.legend()\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spammodel.embedding.weight[spam_vocab.stoi[test_word]].detach().numpy().reshape(-1, 1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}