{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Convolutional neural networks\n",
    "\n",
    "- Add stuff about the intermittent outputs of the conv layers\n",
    "- REmember eto include both max **and** average pooling\n",
    " \n",
    "## Overview\n",
    "*(p. 287 - 321 in Bishop)*\n",
    "\n",
    "\n",
    "CNN’s are a class of Neural networks, typically used in:\n",
    "1. Image analysis: Since the amount of parameters they use is effectively invariant in\n",
    "regards to the size of the image. Moreoever because they can learn to do feature\n",
    "extraction much the same way regular convolution does.\n",
    "2. Time signal analysis: Again, since their number of parameters do not scale with the\n",
    "length of the observed signal. Also again since they can learn to mimic a lot of the\n",
    "convolutions (which is essentially filtering) that have proven themselves useful in\n",
    "the past\n",
    "\n",
    "Like every other neural network class out there, there are a million-and-one specific\n",
    "methods and ideas to improve their performance, of all these, these exercises only ex-\n",
    "plore pooling. Moreoever, there is a billion-and-two different specific architectures that\n",
    "are useful in specific or different cases. Of these, we will only considerVGG16.\n",
    "Even so, with these fundamentals in mind, you should be able to at least understand\n",
    "what it is most other implementations of these neural networks do.\n",
    "\n",
    "\n",
    "\n",
    "**The theoretical exercises are divided into different parts, you do not have to\n",
    "do all in-order, you can jump between them as much as you like. Like always,\n",
    "be sure to ask plenty of ’stupid’ questions; CNN’s probably more than any\n",
    "other subject, has many ”I really should understand this, but I don’t, there-\n",
    "fore I must be dumb”-moments, so don’t sweat it if it seems trivial, it probably\n",
    "isn’t.**\n",
    "\n",
    "Questions marked with * are ”bonus” questions only vaguely related to the\n",
    "core subject, and you will not be expected to know them in an exam setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Convolutional Layers\n",
    "\n",
    "### Exercise 1.1 (ch. 10.2.5)\n",
    "\n",
    "Consider one convolution kernel for a CNN as shown in the image below with the given parameters:\n",
    "- Size: $3 \\times 3$\n",
    "- Padding (zero-padded): $1$\n",
    "- Stride: $1$\n",
    "- Input channels: $3$\n",
    "\n",
    "****1:** How many (learnable) parameters does this kernel have in a CNN?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "\n",
    "****2:** In general, how many parameters does an 𝑛 × 𝑛 kernel with 𝑝 padding and 𝑠 stridehave?** \n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "\n",
    "Say you now have a convolutional layer with the following params:\n",
    "\n",
    "- Kernel size: $n \\times n$\n",
    "- Input channels: $d$\n",
    "- Output channels: $k$\n",
    "\n",
    "\n",
    "**1: How many learnable parameters does this whole convolutional layer have?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "\n",
    "**2: Check your manual calculation against that of the torch implementation below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch thinks there are 2432 parameters in the layer layer \n",
      "Compared to 2432 calculated manually\n"
     ]
    }
   ],
   "source": [
    "# Parameters for convolutional layer\n",
    "in_channels = 3\n",
    "out_channels = 128\n",
    "kernel_size = (2,3) # Does not have to be a tuple, if int, will be converted to a square kernel\n",
    "stride = 1\n",
    "padding = 0\n",
    "bias = True\n",
    "\n",
    "# Define conv layer and sum number of parameters\n",
    "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=True)\n",
    "num_params = sum(p.numel() for p in conv_layer.parameters())\n",
    "\n",
    "# Calculate number of parameters manually\n",
    "num_params_manual = ((in_channels*kernel_size[0]*kernel_size[1] + bias)*out_channels) # ANSWER: (d * m * n + 1) * k\n",
    "\n",
    "# Print results\n",
    "print(f\"Torch thinks there are {num_params} parameters in the layer layer \\nCompared to {num_params_manual} calculated manually\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "\n",
    "Given a convolutional layer with the following parameters:\n",
    "- Size: $n \\times n$\n",
    "- Padding: $p$\n",
    "- Stride: $s$\n",
    "- Input channels: $d$\n",
    "- Output channels: $k$\n",
    "\n",
    "\n",
    "**1. What is the dimensionality of the output? (Do not forget to include the number of\n",
    "channels)**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "\n",
    "**2. Likewise, what is the dimensionality a pooling layer with the same parameters ?**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD ACTUAL NUMBERS EXERCISE HERE (PERHAPS VERIFY WITH TORCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape before convolution: torch.Size([4, 56, 56])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 3, 2, 3], expected input[1, 4, 56, 56] to have 3 channels, but got 4 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m a_cool_image_tensor \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mto_tensor(a_cool_image)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape before convolution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ma_cool_image_tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m a_cool_image_tensor \u001b[38;5;241m=\u001b[39m  \u001b[43mconv_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_cool_image_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;66;03m# Unsqueeze to add batch dimension (because torch is nasty like that)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sign-dat/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sign-dat/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sign-dat/lib/python3.12/site-packages/torch/nn/modules/conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sign-dat/lib/python3.12/site-packages/torch/nn/modules/conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 3, 2, 3], expected input[1, 4, 56, 56] to have 3 channels, but got 4 channels instead"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "import torchvision.transforms\n",
    "import torchvision.transforms.functional\n",
    "\n",
    "\n",
    "a_cool_image = PIL.Image.open(\"a_cool_image.png\")   \n",
    "a_cool_image_tensor = torchvision.transforms.functional.to_tensor(a_cool_image)\n",
    "\n",
    "print(f\"Image shape before convolution: {a_cool_image_tensor.shape}\")\n",
    "\n",
    "a_cool_image_tensor =  conv_layer(a_cool_image_tensor.unsqueeze(0)).shape # Unsqueeze to add batch dimension (because torch is nasty like that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dayman/Signals-And-Data-Autumn-2024/pickle_rick.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mImage\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m PILOpen \u001b[38;5;241m=\u001b[39m \u001b[43mPIL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../pickle_rick.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m PILOpen \u001b[38;5;241m=\u001b[39m PILOpen\u001b[38;5;241m.\u001b[39mresize((\u001b[38;5;241m56\u001b[39m,\u001b[38;5;241m56\u001b[39m), PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mBILINEAR)\n\u001b[1;32m      7\u001b[0m PILOpen\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/miniconda3/envs/sign-dat/lib/python3.12/site-packages/PIL/Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dayman/Signals-And-Data-Autumn-2024/pickle_rick.png'"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "\n",
    "PILOpen = PIL.Image.open(\"../pickle_rick.png\")\n",
    "\n",
    "PILOpen = PILOpen.resize((56,56), PIL.Image.BILINEAR)\n",
    "\n",
    "PILOpen.show()\n",
    "\n",
    "PILOpen.save(\"a_cool_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4\n",
    "\n",
    "*It should be clear now, that each channel in the output image, corresponds to one kernel\n",
    "being run across all channels in the input image. Therefore with $k$ output channels, we\n",
    "have to train $k$ kernels, each with $m \\times n \\times d + 1$ parameters.*\n",
    "\n",
    "**1. Discuss (and write down) the benefits of having a larger number of output channels\n",
    "compared to input channels.**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Increasing the number of output channels in one layer obviously leads to more ker-\n",
    "nels (and therefore more parameters), but how does this increased number of output\n",
    "channels affect the kernels in subsequent layers in a neural network?**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5\n",
    "\n",
    "*If you read the torch documentation of Conv2d: [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html), you won’t find anywhere that\n",
    "it flips the kernel as is otherwise required to go from cross-correlation to convolution.*\n",
    "\n",
    "\n",
    "**1. Explain how PyTorch, a respectable deep learning framework, can get away with *not*\n",
    "flipping the kernel**\n",
    "\n",
    "$\\dots$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1.6\n",
    "\n",
    "*As mentioned, one reason CNN’s are used for image processing, is because they don’t\n",
    "explode in parameter complexity as the input image increases in size. Here we will\n",
    "bastardize the big-O notation from Algorithms and Data structures to denote how the\n",
    "number of parameters in a nerual network increases as a function of relevant hyperpa-\n",
    "rameters.*\n",
    "\n",
    "**1. In the aforementioned big-O, how does the number of parameters in a fully connected,\n",
    "feedforward neural network (FFN) grow as a function of image size (assume multiple\n",
    "input channels)?**\n",
    "\n",
    "$\\dots$\n",
    "\n",
    "**2. Again in the Big-O notation, how does the number of parameters in a CNN grow as a\n",
    "function of image size and other relevant layer hyperparameters?**\n",
    "\n",
    "$\\dots$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary # courtesy of https://stackoverflow.com/questions/55875279/how-to-get-an-output-dimension-for-each-layer-of-the-neural-network-in-pytorch\n",
    "\n",
    "# Check if you have cuda available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist'\n",
    "\n",
    "# TODO: PERHAPS USE THIS, PERHAPS NOT\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=ToTensor())\n",
    "    test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "elif dataset == 'mnist':\n",
    "    train_set = datasets.MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "    test_set = datasets.MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print some stats of the dataset here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n",
    "#            batch_sampler=None, num_workers=0, collate_fn=None,\n",
    "#            pin_memory=False, drop_last=False, timeout=0,\n",
    "#            worker_init_fn=None, *, prefetch_factor=2,\n",
    "#            persistent_workers=False)\n",
    "\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(x_.to(device) for x_ in default_collate(batch))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False, collate_fn=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cifar10_classes = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck'\n",
    "}\n",
    "\n",
    "num_rows = 4\n",
    "num_cols = 5\n",
    "num_images = num_rows * num_cols\n",
    "\n",
    "# Create a figure to display the images\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "fig.suptitle('Train Images and their classes', fontsize=20)\n",
    "\n",
    "\n",
    "p = 0\n",
    "# TODO: Consider if it isn't easier just using variable dataloader size for this bullshit... would save the nested loops, ya'know\n",
    "for imgs, labels in train_dataloader:\n",
    "    for img, label in zip(imgs, labels):\n",
    "        \n",
    "        if p == num_images:\n",
    "            continue\n",
    "\n",
    "        curr_img = img.permute(1, 2, 0).to('cpu').numpy()\n",
    "        # Normalize the image to the range [0, 1]\n",
    "        curr_img = (curr_img - curr_img.min()) / (curr_img.max() - curr_img.min())\n",
    "        axes[p].imshow(curr_img)\n",
    "        axes[p].axis('off')\n",
    "\n",
    "        if dataset == 'cifar10':\n",
    "            axes[p].set_title(cifar10_classes[label.item()], fontsize=12)\n",
    "        elif dataset == 'mnist':\n",
    "            axes[p].set_title(label.item(), fontsize=12)\n",
    "\n",
    "        p += 1\n",
    "\n",
    "    if p == num_images:\n",
    "        break\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNNClass(torch.nn.Module):\n",
    "    def __init__(self, lr=0.001):\n",
    "        if self.__class__ == BaseNNClass:\n",
    "            raise TypeError(f\"{self.__class__.__name__} cannot be instantiated directly.\")\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Consider if we have x.flatten here or in collate_fn\n",
    "        return self.layers(x.flatten(start_dim=1))\n",
    "\n",
    "    def train(self, train_dataloader, epochs=1, val_dataloader=None):\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            for inputs, targets in train_dataloader:\n",
    "                \n",
    "                logits = self.forward(inputs)\n",
    "\n",
    "                loss = self.criterion(logits, targets)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optim.step()\n",
    "\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "            if val_dataloader is not None:\n",
    "                acc = self.eval(val_dataloader)\n",
    "                print(f\"Epoch {epoch} validation accuracy: {acc}\")\n",
    "\n",
    "    def eval(self, test_dataloader):\n",
    "        \n",
    "        total_acc = 0\n",
    "\n",
    "        for input_batch, label_batch in test_dataloader:\n",
    "            # Get predictions\n",
    "            logits = self(input_batch)\n",
    "\n",
    "            # Remember, outs are probabilities (so there's 10 for each input)\n",
    "            # The classification the network wants to assign, must therefore be the probability with the larget value\n",
    "            # We find that using argmax (dim=1, because dim=0 would be across batch dimension)\n",
    "            classifications = torch.argmax(logits, dim=1)\n",
    "            total_acc += (classifications == label_batch).sum().item()\n",
    "\n",
    "        total_acc = total_acc / len(test_dataloader.dataset)\n",
    "\n",
    "        return total_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a convolutional neural network (CNN) class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:24<00:00,  4.83s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9863"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1, lr=0.001):\n",
    "        super().__init__()\n",
    "            \n",
    "        # Remember here, that the amount of parameters in a convolutional layer\n",
    "        # Is (n * m * l + 1) * k\n",
    "        # Where n, m is the kernel size (x, y), l is the input channels, and k is the output channels\n",
    "        # + 1 is beacuse of a bias term that is done for each input\n",
    "        # Basically, n * m * l corresponds to kernels mapping to values in another \"image\"\n",
    "        # This \"image\". Each kernel has a bias term unique to it. Each kernel produces one \"image\", that are then stacked\n",
    "        # on top of each other, for a total of k images.\n",
    "\n",
    "        #CONV2D does NOT flip the kernel!!!\n",
    "        # It doesn't really mattter, since it is just learned anyways...\n",
    "        # Better to maxpool first, max-pooling and monotonely increasing non-linearities commute. This means that MaxPool(Relu(x)) = Relu(MaxPool(x)) for any input\n",
    "        # cite - https://stackoverflow.com/questions/35543428/activation-function-after-pooling-layer-or-convolutional-layer\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1), # dim = in\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64*6*6, out_features=600),\n",
    "            nn.Linear(in_features=600, out_features=120),\n",
    "            nn.Linear(in_features=120, out_features=num_classes)\n",
    "        ).to(device)\n",
    "                \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.optim = torch.optim.Adam(self.layers.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Consider if we have x.flatten here or in collate_fn\n",
    "        return self.layers(x)\n",
    "\n",
    "    def train(self, train_dataloader, epochs=1, val_dataloader=None):\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            for inputs, targets in train_dataloader:\n",
    "                logits = self.forward(inputs)\n",
    "\n",
    "                loss = self.criterion(logits, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "            if val_dataloader is not None:\n",
    "                acc = self.eval(val_dataloader)\n",
    "                print(f\"Epoch {epoch} validation accuracy: {acc}\")\n",
    "\n",
    "    def eval(self, test_dataloader):\n",
    "        \n",
    "        total_acc = 0\n",
    "\n",
    "        for input_batch, label_batch in test_dataloader:\n",
    "            # Get predictions\n",
    "            logits = self(input_batch)\n",
    "\n",
    "            # Remember, outs are probabilities (so there's 10 for each input)\n",
    "            # The classification the network wants to assign, must therefore be the probability with the larget value\n",
    "            # We find that using argmax (dim=1, because dim=0 would be across batch dimension)\n",
    "            classifications = torch.argmax(logits, dim=1)\n",
    "            total_acc += (classifications == label_batch).sum().item()\n",
    "\n",
    "        total_acc = total_acc / len(test_dataloader.dataset)\n",
    "\n",
    "        return total_acc\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(next(iter(train_dataloader))[0].shape)\n",
    "\n",
    "model = CNN(num_classes=10, in_channels=1, lr=0.001)\n",
    "model.train(train_dataloader, epochs=5)\n",
    "model.eval(test_dataloader)\n",
    "\n",
    "# # summary(model, (3, 64, 64))\n",
    "# model.forward_checker(torch.zeros(16, 3, 64, 64))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a feedforward neural network (FFNN) class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:21<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5], device='cuda:0')\n",
      "tensor([9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1], device='cuda:0')\n",
      "tensor([3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2], device='cuda:0')\n",
      "tensor([4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3], device='cuda:0')\n",
      "tensor([7, 4, 6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7], device='cuda:0')\n",
      "tensor([7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4], device='cuda:0')\n",
      "tensor([1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4, 8, 7], device='cuda:0')\n",
      "tensor([3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5], device='cuda:0')\n",
      "tensor([8, 5, 6, 6, 5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1], device='cuda:0')\n",
      "tensor([7, 1, 8, 2, 0, 3, 9, 8, 5, 5, 1, 5, 6, 0, 3, 4], device='cuda:0')\n",
      "tensor([4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7], device='cuda:0')\n",
      "tensor([1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 9, 0, 3, 1, 6, 4, 2, 3, 6, 1, 1, 1, 3, 9, 5], device='cuda:0')\n",
      "tensor([2, 9, 4, 5, 9, 3, 9, 0, 3, 6, 5, 5, 7, 2, 2, 7], device='cuda:0')\n",
      "tensor([1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1], device='cuda:0')\n",
      "tensor([5, 9, 8, 7, 2, 3, 0, 2, 4, 2, 4, 1, 9, 5, 7, 7], device='cuda:0')\n",
      "tensor([2, 8, 2, 0, 8, 5, 7, 7, 9, 1, 8, 1, 8, 0, 3, 0], device='cuda:0')\n",
      "tensor([1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2, 6, 4], device='cuda:0')\n",
      "tensor([1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2], device='cuda:0')\n",
      "tensor([4, 0, 2, 7, 4, 3, 3, 0, 0, 3, 1, 9, 6, 5, 2, 5], device='cuda:0')\n",
      "tensor([9, 7, 9, 3, 0, 4, 2, 0, 7, 1, 1, 2, 1, 5, 3, 3], device='cuda:0')\n",
      "tensor([9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5], device='cuda:0')\n",
      "tensor([5, 6, 1, 8, 5, 1, 7, 9, 4, 6, 2, 2, 5, 0, 6, 5], device='cuda:0')\n",
      "tensor([6, 3, 7, 2, 0, 8, 8, 5, 4, 1, 1, 4, 0, 7, 3, 7], device='cuda:0')\n",
      "tensor([6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5, 2, 5, 4, 4], device='cuda:0')\n",
      "tensor([2, 8, 3, 8, 2, 4, 5, 0, 3, 1, 7, 7, 3, 7, 9, 7], device='cuda:0')\n",
      "tensor([1, 9, 2, 1, 4, 3, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8], device='cuda:0')\n",
      "tensor([4, 5, 9, 8, 8, 3, 7, 6, 0, 0, 3, 0, 2, 0, 6, 4], device='cuda:0')\n",
      "tensor([8, 3, 3, 3, 2, 3, 9, 1, 2, 6, 8, 0, 5, 6, 6, 6], device='cuda:0')\n",
      "tensor([7, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9], device='cuda:0')\n",
      "tensor([1, 9, 7, 5, 4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 0], device='cuda:0')\n",
      "tensor([9, 4, 0, 6, 3, 9, 5, 2, 1, 3, 1, 3, 6, 5, 7, 4], device='cuda:0')\n",
      "tensor([2, 2, 6, 3, 2, 6, 5, 4, 8, 9, 7, 1, 3, 0, 3, 8], device='cuda:0')\n",
      "tensor([3, 1, 9, 3, 4, 4, 6, 4, 2, 1, 8, 2, 5, 4, 8, 8], device='cuda:0')\n",
      "tensor([4, 0, 0, 2, 3, 2, 7, 7, 0, 8, 7, 4, 4, 7, 9, 6], device='cuda:0')\n",
      "tensor([9, 7, 9, 8, 0, 4, 6, 0, 6, 3, 5, 4, 8, 3, 3, 9], device='cuda:0')\n",
      "tensor([3, 3, 3, 7, 8, 0, 2, 8, 1, 7, 0, 6, 5, 4, 3, 8], device='cuda:0')\n",
      "tensor([0, 9, 6, 3, 8, 0, 9, 9, 6, 8, 6, 8, 5, 7, 8, 6], device='cuda:0')\n",
      "tensor([0, 2, 8, 0, 2, 8, 3, 1, 9, 7, 5, 1, 0, 8, 4, 6], device='cuda:0')\n",
      "tensor([2, 6, 7, 9, 3, 2, 9, 8, 2, 2, 9, 2, 7, 3, 5, 9], device='cuda:0')\n",
      "tensor([1, 8, 0, 2, 0, 5, 2, 1, 3, 7, 6, 7, 1, 2, 5, 8], device='cuda:0')\n",
      "tensor([0, 3, 7, 8, 4, 0, 9, 1, 8, 6, 7, 2, 4, 3, 4, 9], device='cuda:0')\n",
      "tensor([1, 9, 5, 1, 7, 3, 9, 7, 6, 9, 1, 3, 7, 8, 3, 3], device='cuda:0')\n",
      "tensor([6, 7, 2, 8, 5, 8, 5, 1, 1, 4, 4, 3, 1, 0, 7, 7], device='cuda:0')\n",
      "tensor([0, 7, 9, 4, 4, 8, 5, 5, 4, 0, 8, 2, 1, 0, 8, 4], device='cuda:0')\n",
      "tensor([8, 0, 4, 0, 6, 1, 9, 3, 2, 6, 7, 2, 6, 9, 3, 1], device='cuda:0')\n",
      "tensor([4, 6, 2, 5, 9, 2, 0, 6, 2, 1, 7, 3, 4, 1, 0, 5], device='cuda:0')\n",
      "tensor([4, 3, 1, 1, 7, 4, 9, 9, 9, 8, 4, 0, 2, 4, 5, 1], device='cuda:0')\n",
      "tensor([1, 6, 4, 7, 1, 9, 4, 2, 4, 1, 5, 5, 3, 8, 3, 1], device='cuda:0')\n",
      "tensor([4, 5, 6, 8, 9, 4, 1, 5, 3, 8, 0, 3, 2, 5, 1, 2], device='cuda:0')\n",
      "tensor([8, 3, 4, 4, 0, 8, 8, 3, 3, 1, 7, 3, 5, 9, 6, 3], device='cuda:0')\n",
      "tensor([2, 6, 1, 3, 6, 0, 7, 2, 1, 7, 1, 4, 2, 4, 2, 1], device='cuda:0')\n",
      "tensor([7, 9, 6, 1, 1, 2, 4, 8, 1, 7, 7, 4, 8, 0, 7, 3], device='cuda:0')\n",
      "tensor([1, 3, 1, 0, 7, 7, 0, 3, 5, 5, 2, 7, 6, 6, 9, 2], device='cuda:0')\n",
      "tensor([8, 3, 5, 2, 2, 5, 6, 0, 8, 2, 9, 2, 8, 6, 8, 8], device='cuda:0')\n",
      "tensor([7, 9, 9, 3, 0, 6, 6, 3, 2, 1, 3, 2, 2, 9, 3, 0], device='cuda:0')\n",
      "tensor([0, 5, 7, 8, 3, 4, 4, 6, 0, 2, 9, 1, 4, 7, 4, 7], device='cuda:0')\n",
      "tensor([3, 9, 8, 8, 4, 7, 1, 2, 1, 2, 2, 3, 7, 3, 2, 3], device='cuda:0')\n",
      "tensor([9, 1, 7, 4, 0, 3, 5, 5, 8, 6, 3, 2, 6, 7, 6, 6], device='cuda:0')\n",
      "tensor([3, 2, 7, 8, 1, 1, 7, 4, 6, 4, 9, 5, 2, 3, 3, 4], device='cuda:0')\n",
      "tensor([7, 8, 9, 1, 1, 0, 9, 1, 4, 4, 5, 4, 0, 6, 2, 2], device='cuda:0')\n",
      "tensor([3, 1, 5, 1, 2, 0, 3, 8, 1, 2, 6, 7, 1, 6, 2, 3], device='cuda:0')\n",
      "tensor([9, 0, 1, 2, 2, 0, 8, 9, 9, 0, 2, 5, 1, 9, 7, 8], device='cuda:0')\n",
      "tensor([1, 0, 4, 1, 7, 9, 5, 4, 2, 6, 8, 1, 3, 7, 5, 4], device='cuda:0')\n",
      "tensor([4, 1, 8, 1, 3, 8, 1, 2, 5, 8, 0, 6, 2, 1, 1, 7], device='cuda:0')\n",
      "tensor([1, 5, 3, 4, 6, 9, 5, 0, 9, 2, 3, 4, 8, 2, 1, 7], device='cuda:0')\n",
      "tensor([2, 4, 9, 4, 4, 0, 3, 9, 2, 2, 3, 3, 8, 3, 5, 7], device='cuda:0')\n",
      "tensor([3, 5, 8, 1, 2, 4, 4, 6, 4, 9, 5, 1, 0, 6, 9, 5], device='cuda:0')\n",
      "tensor([9, 5, 9, 7, 3, 8, 0, 3, 7, 1, 3, 6, 7, 8, 5, 9], device='cuda:0')\n",
      "tensor([7, 9, 6, 5, 6, 3, 7, 4, 6, 5, 8, 5, 4, 7, 8, 7], device='cuda:0')\n",
      "tensor([8, 0, 7, 6, 8, 8, 7, 3, 7, 1, 9, 5, 2, 7, 3, 5], device='cuda:0')\n",
      "tensor([1, 1, 2, 1, 4, 7, 4, 7, 5, 4, 5, 4, 0, 8, 3, 6], device='cuda:0')\n",
      "tensor([9, 6, 0, 2, 8, 4, 4, 4, 4, 6, 6, 4, 7, 9, 3, 4], device='cuda:0')\n",
      "tensor([5, 5, 8, 7, 3, 7, 2, 7, 0, 2, 4, 1, 1, 1, 6, 9], device='cuda:0')\n",
      "tensor([2, 8, 7, 2, 0, 1, 5, 0, 4, 1, 7, 0, 6, 0, 8, 6], device='cuda:0')\n",
      "tensor([8, 1, 8, 0, 3, 3, 7, 2, 3, 6, 2, 1, 6, 1, 1, 3], device='cuda:0')\n",
      "tensor([7, 9, 0, 8, 0, 5, 4, 0, 2, 8, 2, 2, 9, 8, 4, 0], device='cuda:0')\n",
      "tensor([4, 5, 8, 5, 1, 2, 1, 3, 1, 7, 4, 5, 7, 2, 0, 5], device='cuda:0')\n",
      "tensor([8, 8, 6, 2, 5, 6, 1, 9, 2, 1, 5, 8, 1, 0, 2, 9], device='cuda:0')\n",
      "tensor([4, 3, 6, 8, 8, 2, 4, 0, 5, 0, 4, 4, 7, 9, 3, 4], device='cuda:0')\n",
      "tensor([1, 5, 9, 2, 3, 5, 8, 8, 0, 9, 3, 3, 6, 6, 0, 1], device='cuda:0')\n",
      "tensor([6, 0, 3, 7, 4, 4, 1, 2, 9, 1, 4, 6, 9, 9, 3, 9], device='cuda:0')\n",
      "tensor([8, 4, 4, 3, 1, 3, 1, 3, 8, 7, 9, 4, 8, 8, 8, 9], device='cuda:0')\n",
      "tensor([9, 1, 4, 5, 6, 0, 5, 2, 2, 2, 1, 5, 5, 2, 4, 9], device='cuda:0')\n",
      "tensor([6, 2, 7, 7, 2, 2, 1, 1, 2, 8, 3, 7, 2, 4, 1, 7], device='cuda:0')\n",
      "tensor([1, 7, 6, 7, 8, 2, 7, 3, 1, 7, 5, 8, 2, 6, 2, 2], device='cuda:0')\n",
      "tensor([5, 6, 6, 0, 9, 2, 4, 3, 3, 9, 7, 6, 6, 8, 0, 9], device='cuda:0')\n",
      "tensor([1, 3, 8, 2, 9, 1, 8, 0, 6, 7, 2, 1, 0, 5, 5, 2], device='cuda:0')\n",
      "tensor([0, 2, 2, 0, 2, 9, 7, 8, 0, 9, 9, 4, 6, 5, 4, 9], device='cuda:0')\n",
      "tensor([1, 8, 3, 4, 9, 9, 1, 2, 2, 8, 1, 9, 6, 4, 0, 9], device='cuda:0')\n",
      "tensor([4, 8, 3, 8, 4, 0, 2, 5, 1, 9, 6, 2, 9, 4, 0, 9], device='cuda:0')\n",
      "tensor([6, 0, 6, 2, 5, 4, 2, 3, 8, 4, 5, 5, 0, 3, 8, 5], device='cuda:0')\n",
      "tensor([3, 5, 8, 6, 3, 7, 6, 3, 3, 9, 6, 1, 1, 2, 9, 0], device='cuda:0')\n",
      "tensor([4, 3, 3, 6, 9, 5, 7, 3, 7, 7, 7, 8, 1, 9, 8, 3], device='cuda:0')\n",
      "tensor([0, 7, 2, 7, 9, 4, 5, 4, 9, 3, 2, 1, 4, 0, 2, 3], device='cuda:0')\n",
      "tensor([7, 5, 9, 8, 8, 5, 0, 3, 1, 4, 7, 5, 9, 0, 0, 0], device='cuda:0')\n",
      "tensor([6, 6, 2, 3, 7, 8, 4, 7, 7, 9, 2, 4, 1, 6, 5, 2], device='cuda:0')\n",
      "tensor([4, 9, 9, 1, 8, 4, 0, 9, 8, 4, 8, 7, 7, 0, 7, 8], device='cuda:0')\n",
      "tensor([8, 6, 0, 4, 8, 8, 2, 4, 7, 6, 6, 6, 4, 7, 1, 8], device='cuda:0')\n",
      "tensor([8, 2, 3, 6, 3, 0, 0, 3, 7, 6, 9, 7, 9, 9, 5, 4], device='cuda:0')\n",
      "tensor([3, 7, 6, 1, 2, 3, 7, 3, 3, 6, 0, 3, 3, 8, 4, 3], device='cuda:0')\n",
      "tensor([6, 3, 5, 0, 2, 0, 9, 0, 7, 4, 5, 9, 3, 5, 1, 9], device='cuda:0')\n",
      "tensor([6, 1, 4, 5, 4, 5, 0, 5, 9, 5, 2, 1, 2, 9, 1, 9], device='cuda:0')\n",
      "tensor([9, 4, 0, 8, 4, 5, 2, 9, 2, 1, 2, 1, 7, 3, 6, 8], device='cuda:0')\n",
      "tensor([8, 4, 9, 1, 9, 8, 3, 7, 5, 1, 1, 8, 6, 5, 0, 4], device='cuda:0')\n",
      "tensor([4, 7, 2, 3, 5, 6, 8, 8, 6, 2, 3, 1, 0, 5, 8, 9], device='cuda:0')\n",
      "tensor([2, 9, 6, 7, 0, 4, 8, 7, 1, 7, 4, 1, 0, 9, 7, 2], device='cuda:0')\n",
      "tensor([0, 0, 9, 1, 7, 8, 7, 8, 4, 7, 2, 0, 4, 6, 0, 3], device='cuda:0')\n",
      "tensor([1, 1, 3, 3, 9, 6, 7, 4, 1, 5, 3, 0, 8, 7, 3, 9], device='cuda:0')\n",
      "tensor([6, 9, 3, 5, 0, 2, 7, 2, 5, 1, 2, 5, 8, 0, 8, 8], device='cuda:0')\n",
      "tensor([1, 9, 0, 3, 0, 3, 1, 4, 0, 3, 7, 2, 7, 1, 8, 0], device='cuda:0')\n",
      "tensor([7, 0, 4, 3, 1, 9, 8, 7, 7, 1, 4, 9, 9, 3, 7, 1], device='cuda:0')\n",
      "tensor([7, 9, 0, 2, 0, 3, 3, 7, 6, 9, 2, 3, 3, 7, 7, 0], device='cuda:0')\n",
      "tensor([0, 7, 5, 2, 9, 8, 7, 4, 4, 2, 6, 6, 1, 9, 6, 8], device='cuda:0')\n",
      "tensor([2, 9, 0, 8, 9, 1, 1, 6, 3, 5, 1, 1, 1, 3, 1, 2], device='cuda:0')\n",
      "tensor([3, 0, 2, 0, 1, 3, 5, 5, 7, 4, 3, 9, 6, 9, 6, 8], device='cuda:0')\n",
      "tensor([3, 6, 6, 8, 5, 1, 4, 2, 4, 4, 5, 1, 1, 9, 0, 2], device='cuda:0')\n",
      "tensor([4, 9, 5, 7, 1, 8, 8, 5, 6, 9, 8, 7, 1, 1, 6, 7], device='cuda:0')\n",
      "tensor([6, 3, 2, 2, 0, 8, 9, 2, 5, 1, 0, 8, 1, 4, 5, 7], device='cuda:0')\n",
      "tensor([9, 6, 9, 0, 6, 1, 5, 5, 8, 3, 8, 2, 6, 5, 0, 7], device='cuda:0')\n",
      "tensor([4, 6, 1, 3, 4, 7, 3, 2, 3, 4, 2, 5, 2, 7, 1, 7], device='cuda:0')\n",
      "tensor([2, 6, 6, 1, 5, 8, 8, 6, 0, 1, 8, 2, 5, 7, 7, 6], device='cuda:0')\n",
      "tensor([9, 3, 5, 2, 4, 2, 4, 0, 8, 8, 3, 4, 9, 2, 7, 5], device='cuda:0')\n",
      "tensor([8, 6, 5, 6, 0, 8, 6, 7, 3, 6, 4, 9, 4, 6, 6, 3], device='cuda:0')\n",
      "tensor([0, 4, 1, 0, 1, 4, 6, 2, 9, 1, 1, 0, 6, 3, 9, 5], device='cuda:0')\n",
      "tensor([6, 5, 6, 5, 9, 4, 6, 4, 3, 9, 1, 3, 4, 1, 9, 1], device='cuda:0')\n",
      "tensor([2, 1, 1, 9, 3, 5, 4, 0, 9, 3, 6, 1, 7, 5, 5, 3], device='cuda:0')\n",
      "tensor([3, 0, 1, 5, 7, 5, 8, 6, 5, 1, 0, 8, 2, 3, 4, 6], device='cuda:0')\n",
      "tensor([7, 9, 8, 1, 8, 9, 9, 2, 8, 6, 2, 7, 0, 0, 6, 7], device='cuda:0')\n",
      "tensor([5, 8, 6, 0, 9, 3, 7, 1, 3, 0, 4, 3, 3, 5, 5, 6], device='cuda:0')\n",
      "tensor([3, 0, 2, 3, 4, 2, 3, 0, 9, 9, 4, 7, 2, 8, 4, 7], device='cuda:0')\n",
      "tensor([0, 6, 2, 8, 5, 2, 8, 5, 7, 3, 0, 8, 2, 2, 2, 8], device='cuda:0')\n",
      "tensor([2, 5, 5, 7, 6, 4, 0, 8, 4, 8, 2, 7, 4, 9, 2, 0], device='cuda:0')\n",
      "tensor([3, 7, 9, 6, 7, 2, 5, 1, 1, 1, 2, 3, 6, 7, 8, 7], device='cuda:0')\n",
      "tensor([6, 4, 8, 9, 4, 8, 6, 3, 8, 3, 1, 0, 6, 2, 2, 5], device='cuda:0')\n",
      "tensor([6, 9, 8, 8, 1, 4, 1, 7, 8, 4, 6, 1, 8, 4, 3, 1], device='cuda:0')\n",
      "tensor([2, 8, 0, 8, 5, 9, 2, 4, 2, 0, 2, 7, 0, 9, 0, 2], device='cuda:0')\n",
      "tensor([5, 7, 6, 7, 9, 4, 2, 6, 2, 4, 4, 8, 0, 4, 4, 5], device='cuda:0')\n",
      "tensor([8, 0, 6, 8, 9, 8, 5, 6, 9, 0, 4, 8, 7, 1, 3, 4], device='cuda:0')\n",
      "tensor([5, 8, 0, 9, 1, 3, 3, 6, 9, 8, 7, 1, 0, 8, 7, 1], device='cuda:0')\n",
      "tensor([7, 5, 2, 7, 9, 1, 8, 5, 2, 4, 9, 4, 7, 2, 2, 3], device='cuda:0')\n",
      "tensor([4, 9, 1, 9, 2, 1, 7, 9, 4, 4, 3, 6, 7, 2, 7, 8], device='cuda:0')\n",
      "tensor([0, 1, 9, 7, 1, 1, 7, 5, 3, 3, 5, 1, 3, 7, 6, 1], device='cuda:0')\n",
      "tensor([3, 8, 7, 3, 9, 6, 0, 0, 2, 8, 8, 2, 3, 7, 1, 3], device='cuda:0')\n",
      "tensor([0, 3, 4, 4, 3, 8, 9, 2, 3, 9, 7, 1, 1, 7, 0, 4], device='cuda:0')\n",
      "tensor([9, 6, 5, 9, 1, 2, 5, 2, 0, 2, 4, 6, 7, 0, 7, 1], device='cuda:0')\n",
      "tensor([4, 6, 4, 5, 4, 9, 9, 1, 7, 9, 5, 3, 3, 8, 2, 3], device='cuda:0')\n",
      "tensor([6, 2, 2, 1, 1, 1, 1, 1, 6, 9, 8, 4, 3, 7, 1, 6], device='cuda:0')\n",
      "tensor([4, 9, 0, 9, 7, 4, 2, 4, 0, 7, 0, 1, 9, 8, 8, 6], device='cuda:0')\n",
      "tensor([0, 0, 4, 1, 6, 8, 2, 2, 3, 8, 4, 8, 2, 2, 1, 7], device='cuda:0')\n",
      "tensor([5, 4, 4, 0, 4, 3, 1, 7, 9, 1, 0, 1, 2, 5, 4, 2], device='cuda:0')\n",
      "tensor([1, 0, 1, 8, 9, 1, 8, 8, 3, 8, 9, 3, 6, 2, 8, 3], device='cuda:0')\n",
      "tensor([2, 1, 1, 0, 4, 2, 9, 2, 4, 3, 7, 9, 1, 5, 2, 4], device='cuda:0')\n",
      "tensor([9, 0, 3, 8, 5, 3, 6, 0, 9, 4, 6, 2, 5, 0, 2, 7], device='cuda:0')\n",
      "tensor([4, 6, 6, 8, 6, 6, 8, 6, 9, 1, 7, 2, 5, 9, 9, 0], device='cuda:0')\n",
      "tensor([7, 2, 7, 6, 7, 0, 6, 5, 4, 4, 7, 2, 0, 9, 9, 2], device='cuda:0')\n",
      "tensor([2, 9, 4, 4, 2, 3, 3, 2, 1, 7, 0, 7, 6, 4, 1, 3], device='cuda:0')\n",
      "tensor([8, 7, 4, 5, 9, 2, 5, 1, 8, 7, 3, 7, 1, 5, 3, 0], device='cuda:0')\n",
      "tensor([9, 1, 4, 0, 6, 3, 3, 6, 0, 4, 9, 7, 5, 1, 6, 8], device='cuda:0')\n",
      "tensor([9, 5, 5, 7, 9, 3, 8, 3, 8, 1, 5, 3, 5, 0, 5, 5], device='cuda:0')\n",
      "tensor([3, 8, 6, 7, 7, 7, 3, 7, 0, 5, 9, 0, 2, 5, 5, 3], device='cuda:0')\n",
      "tensor([1, 7, 7, 8, 6, 5, 5, 3, 8, 9, 5, 3, 7, 9, 1, 7], device='cuda:0')\n",
      "tensor([0, 0, 3, 7, 2, 5, 8, 1, 8, 6, 2, 9, 5, 7, 5, 1], device='cuda:0')\n",
      "tensor([8, 6, 2, 5, 1, 4, 8, 4, 5, 8, 3, 0, 6, 2, 7, 3], device='cuda:0')\n",
      "tensor([3, 2, 1, 0, 7, 3, 4, 0, 3, 9, 3, 2, 8, 9, 0, 3], device='cuda:0')\n",
      "tensor([8, 0, 7, 6, 5, 4, 7, 3, 5, 0, 8, 6, 2, 5, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 4, 4, 0, 1, 2, 3, 2, 7, 7, 8, 5, 2, 5, 7], device='cuda:0')\n",
      "tensor([6, 9, 1, 4, 1, 6, 4, 2, 4, 3, 5, 4, 3, 9, 5, 0], device='cuda:0')\n",
      "tensor([1, 5, 3, 8, 9, 1, 9, 7, 9, 5, 5, 2, 7, 4, 6, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 4, 4, 7, 6, 3, 0, 0, 4, 3, 0, 6, 1], device='cuda:0')\n",
      "tensor([4, 6, 1, 3, 8, 1, 2, 5, 6, 2, 7, 3, 6, 0, 1, 9], device='cuda:0')\n",
      "tensor([7, 6, 6, 8, 9, 2, 9, 5, 8, 3, 1, 0, 0, 7, 6, 6], device='cuda:0')\n",
      "tensor([2, 1, 6, 9, 3, 1, 8, 6, 9, 0, 6, 0, 0, 0, 6, 3], device='cuda:0')\n",
      "tensor([5, 9, 7, 9, 5, 5, 8, 5, 3, 0, 4, 0, 2, 9, 6, 8], device='cuda:0')\n",
      "tensor([2, 3, 1, 2, 1, 1, 5, 6, 9, 8, 0, 6, 6, 5, 5, 3], device='cuda:0')\n",
      "tensor([8, 6, 2, 1, 4, 5, 4, 3, 7, 8, 5, 0, 9, 3, 5, 1], device='cuda:0')\n",
      "tensor([1, 0, 4, 4, 7, 0, 1, 7, 0, 1, 6, 1, 4, 5, 6, 6], device='cuda:0')\n",
      "tensor([5, 7, 8, 4, 7, 7, 2, 5, 3, 7, 0, 7, 7, 9, 6, 4], device='cuda:0')\n",
      "tensor([2, 8, 5, 7, 8, 3, 9, 5, 8, 9, 9, 8, 6, 2, 8, 9], device='cuda:0')\n",
      "tensor([2, 3, 6, 1, 1, 8, 9, 3, 4, 0, 7, 9, 6, 7, 1, 4], device='cuda:0')\n",
      "tensor([1, 3, 4, 9, 3, 1, 4, 7, 7, 4, 7, 2, 9, 3, 0, 8], device='cuda:0')\n",
      "tensor([8, 8, 4, 0, 4, 4, 1, 5, 2, 8, 3, 4, 9, 5, 2, 8], device='cuda:0')\n",
      "tensor([1, 5, 3, 3, 9, 4, 2, 5, 6, 2, 5, 9, 3, 5, 9, 2], device='cuda:0')\n",
      "tensor([1, 9, 5, 3, 0, 6, 9, 8, 4, 0, 4, 7, 2, 9, 0, 1], device='cuda:0')\n",
      "tensor([0, 3, 1, 6, 5, 8, 1, 5, 3, 3, 0, 3, 5, 5, 9, 2], device='cuda:0')\n",
      "tensor([8, 7, 0, 4, 9, 1, 9, 7, 7, 5, 5, 2, 0, 9, 1, 8], device='cuda:0')\n",
      "tensor([6, 2, 3, 7, 6, 2, 1, 9, 1, 3, 5, 5, 0, 3, 8, 3], device='cuda:0')\n",
      "tensor([3, 7, 6, 5, 0, 1, 4, 0, 6, 9, 8, 1, 2, 9, 9, 5], device='cuda:0')\n",
      "tensor([9, 7, 3, 7, 8, 0, 1, 3, 0, 4, 6, 1, 0, 2, 5, 8], device='cuda:0')\n",
      "tensor([4, 4, 1, 1, 5, 4, 6, 6, 0, 6, 9, 2, 6, 2, 7, 1], device='cuda:0')\n",
      "tensor([7, 9, 4, 0, 0, 3, 8, 2, 2, 3, 1, 6, 0, 5, 7, 7], device='cuda:0')\n",
      "tensor([9, 2, 6, 7, 3, 7, 8, 6, 8, 8, 4, 6, 8, 4, 1, 2], device='cuda:0')\n",
      "tensor([8, 2, 3, 9, 4, 0, 3, 7, 3, 2, 3, 3, 7, 3, 4, 0], device='cuda:0')\n",
      "tensor([6, 2, 0, 8, 1, 5, 3, 5, 4, 1, 7, 1, 5, 7, 5, 7], device='cuda:0')\n",
      "tensor([3, 2, 2, 7, 3, 7, 3, 7, 8, 5, 6, 5, 2, 9, 6, 5], device='cuda:0')\n",
      "tensor([3, 6, 2, 4, 1, 7, 1, 5, 2, 3, 6, 3, 1, 4, 2, 6], device='cuda:0')\n",
      "tensor([7, 4, 3, 8, 0, 6, 2, 1, 6, 5, 3, 9, 1, 9, 3, 2], device='cuda:0')\n",
      "tensor([1, 8, 4, 4, 6, 5, 8, 6, 9, 7, 7, 8, 6, 9, 7, 3], device='cuda:0')\n",
      "tensor([9, 4, 0, 5, 4, 6, 4, 1, 2, 3, 0, 0, 2, 6, 6, 5], device='cuda:0')\n",
      "tensor([7, 0, 8, 6, 4, 7, 9, 0, 7, 3, 4, 2, 1, 8, 8, 5], device='cuda:0')\n",
      "tensor([9, 2, 7, 1, 8, 8, 8, 2, 7, 6, 0, 1, 2, 7, 1, 0], device='cuda:0')\n",
      "tensor([8, 3, 5, 0, 5, 3, 6, 2, 8, 7, 0, 1, 4, 2, 1, 1], device='cuda:0')\n",
      "tensor([4, 4, 4, 4, 7, 1, 6, 2, 9, 9, 0, 0, 1, 8, 8, 4], device='cuda:0')\n",
      "tensor([3, 4, 2, 7, 6, 1, 6, 1, 2, 2, 2, 1, 2, 3, 7, 8], device='cuda:0')\n",
      "tensor([1, 0, 0, 2, 1, 6, 6, 0, 1, 6, 2, 5, 1, 7, 4, 8], device='cuda:0')\n",
      "tensor([2, 1, 4, 3, 8, 3, 9, 9, 4, 8, 3, 4, 7, 2, 7, 5], device='cuda:0')\n",
      "tensor([7, 0, 4, 3, 3, 2, 6, 7, 6, 0, 0, 6, 7, 7, 0, 5], device='cuda:0')\n",
      "tensor([5, 8, 1, 0, 7, 0, 2, 8, 1, 5, 0, 8, 8, 0, 3, 2], device='cuda:0')\n",
      "tensor([7, 7, 8, 6, 4, 7, 5, 5, 5, 2, 9, 2, 8, 4, 6, 8], device='cuda:0')\n",
      "tensor([6, 5, 0, 0, 8, 7, 6, 1, 7, 1, 1, 2, 7, 4, 0, 0], device='cuda:0')\n",
      "tensor([7, 7, 6, 3, 8, 6, 4, 2, 0, 9, 4, 0, 5, 7, 8, 3], device='cuda:0')\n",
      "tensor([9, 4, 7, 1, 1, 3, 6, 6, 2, 9, 1, 9, 4, 8, 3, 6], device='cuda:0')\n",
      "tensor([9, 5, 9, 6, 2, 4, 6, 7, 7, 0, 6, 6, 9, 9, 8, 3], device='cuda:0')\n",
      "tensor([5, 3, 4, 9, 0, 0, 5, 2, 5, 0, 7, 1, 1, 1, 0, 7], device='cuda:0')\n",
      "tensor([6, 7, 9, 6, 6, 4, 1, 4, 3, 1, 1, 2, 2, 4, 1, 0], device='cuda:0')\n",
      "tensor([8, 7, 6, 3, 4, 0, 0, 6, 3, 3, 0, 3, 1, 7, 1, 1], device='cuda:0')\n",
      "tensor([3, 1, 0, 9, 9, 7, 5, 4, 1, 4, 8, 9, 5, 3, 5, 1], device='cuda:0')\n",
      "tensor([9, 8, 2, 7, 3, 9, 9, 0, 1, 0, 2, 9, 3, 9, 3, 3], device='cuda:0')\n",
      "tensor([6, 2, 9, 9, 8, 3, 7, 4, 0, 4, 7, 8, 4, 9, 8, 1], device='cuda:0')\n",
      "tensor([9, 7, 5, 9, 2, 8, 2, 2, 0, 2, 2, 3, 8, 4, 6, 8], device='cuda:0')\n",
      "tensor([4, 8, 2, 4, 6, 7, 9, 3, 3, 9, 4, 3, 1, 4, 4, 7], device='cuda:0')\n",
      "tensor([0, 5, 9, 6, 0, 4, 4, 4, 4, 6, 1, 2, 3, 2, 6, 4], device='cuda:0')\n",
      "tensor([5, 9, 6, 8, 5, 6, 0, 8, 6, 4, 1, 8, 6, 5, 2, 5], device='cuda:0')\n",
      "tensor([4, 5, 5, 4, 7, 7, 7, 7, 8, 2, 2, 3, 7, 0, 1, 8], device='cuda:0')\n",
      "tensor([0, 7, 1, 9, 8, 7, 5, 5, 9, 1, 7, 5, 4, 3, 1, 2], device='cuda:0')\n",
      "tensor([2, 1, 6, 6, 7, 1, 1, 4, 0, 7, 4, 2, 4, 0, 6, 4], device='cuda:0')\n",
      "tensor([7, 6, 9, 5, 3, 4, 6, 5, 0, 1, 8, 8, 2, 8, 3, 5], device='cuda:0')\n",
      "tensor([7, 8, 0, 8, 5, 7, 1, 1, 0, 1, 3, 7, 8, 5, 0, 7], device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 4, 5, 2, 7, 6, 2, 3, 0, 2, 8, 5], device='cuda:0')\n",
      "tensor([9, 6, 9, 7, 2, 1, 3, 6, 4, 1, 3, 2, 4, 0, 5, 1], device='cuda:0')\n",
      "tensor([0, 3, 2, 6, 4, 4, 3, 9, 6, 1, 6, 5, 7, 9, 2, 0], device='cuda:0')\n",
      "tensor([2, 6, 0, 1, 4, 3, 8, 2, 8, 8, 0, 8, 8, 9, 0, 9], device='cuda:0')\n",
      "tensor([6, 7, 6, 3, 9, 3, 9, 7, 7, 7, 4, 9, 0, 6, 4, 8], device='cuda:0')\n",
      "tensor([4, 2, 7, 2, 8, 1, 0, 0, 7, 8, 3, 3, 3, 1, 3, 7], device='cuda:0')\n",
      "tensor([6, 1, 3, 1, 6, 6, 5, 2, 4, 7, 5, 9, 5, 8, 4, 9], device='cuda:0')\n",
      "tensor([9, 1, 6, 5, 0, 1, 3, 7, 0, 3, 4, 8, 2, 2, 0, 2], device='cuda:0')\n",
      "tensor([8, 1, 5, 1, 6, 8, 8, 9, 1, 2, 1, 3, 5, 1, 0, 9], device='cuda:0')\n",
      "tensor([4, 4, 8, 3, 2, 5, 9, 7, 6, 6, 2, 0, 0, 0, 5, 8], device='cuda:0')\n",
      "tensor([8, 1, 5, 3, 3, 8, 5, 1, 8, 2, 0, 4, 9, 9, 6, 2], device='cuda:0')\n",
      "tensor([3, 3, 5, 6, 4, 8, 0, 9, 2, 8, 3, 6, 7, 5, 1, 2], device='cuda:0')\n",
      "tensor([9, 4, 9, 1, 2, 8, 6, 0, 7, 0, 9, 1, 1, 6, 7, 5], device='cuda:0')\n",
      "tensor([9, 9, 1, 9, 5, 9, 2, 5, 0, 4, 1, 0, 8, 4, 0, 8], device='cuda:0')\n",
      "tensor([9, 8, 9, 4, 2, 5, 7, 9, 8, 9, 8, 0, 9, 9, 6, 8], device='cuda:0')\n",
      "tensor([9, 9, 5, 9, 8, 5, 1, 0, 3, 3, 5, 2, 1, 6, 3, 0], device='cuda:0')\n",
      "tensor([2, 8, 3, 5, 6, 2, 3, 0, 2, 2, 6, 4, 3, 5, 5, 1], device='cuda:0')\n",
      "tensor([7, 2, 1, 6, 9, 1, 9, 9, 5, 5, 1, 6, 2, 2, 8, 6], device='cuda:0')\n",
      "tensor([7, 1, 4, 6, 0, 6, 0, 3, 3, 2, 8, 3, 6, 8, 9, 2], device='cuda:0')\n",
      "tensor([5, 3, 8, 5, 4, 5, 2, 0, 5, 6, 3, 2, 8, 3, 9, 9], device='cuda:0')\n",
      "tensor([3, 7, 9, 4, 6, 7, 1, 3, 1, 3, 6, 6, 0, 9, 0, 1], device='cuda:0')\n",
      "tensor([9, 4, 2, 8, 8, 0, 1, 6, 9, 7, 5, 3, 4, 7, 4, 9], device='cuda:0')\n",
      "tensor([8, 4, 3, 6, 3, 1, 1, 7, 6, 9, 1, 8, 4, 1, 1, 9], device='cuda:0')\n",
      "tensor([9, 4, 3, 6, 8, 1, 6, 0, 4, 1, 3, 7, 7, 4, 9, 5], device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 6, 2, 1, 9, 8, 4, 0, 3, 6, 4, 9], device='cuda:0')\n",
      "tensor([0, 7, 1, 6, 5, 7, 5, 2, 5, 1, 8, 5, 4, 7, 0, 6], device='cuda:0')\n",
      "tensor([7, 2, 2, 5, 8, 1, 0, 4, 5, 7, 1, 5, 5, 1, 3, 0], device='cuda:0')\n",
      "tensor([0, 6, 0, 7, 3, 1, 8, 3, 9, 7, 0, 0, 8, 9, 5, 9], device='cuda:0')\n",
      "tensor([8, 3, 2, 7, 2, 9, 7, 2, 1, 1, 3, 7, 5, 3, 1, 9], device='cuda:0')\n",
      "tensor([8, 2, 2, 2, 8, 8, 5, 7, 3, 8, 9, 3, 8, 6, 8, 2], device='cuda:0')\n",
      "tensor([3, 9, 7, 5, 6, 2, 9, 2, 8, 8, 1, 6, 8, 8, 7, 9], device='cuda:0')\n",
      "tensor([1, 8, 0, 1, 7, 2, 0, 7, 5, 1, 9, 0, 2, 0, 9, 8], device='cuda:0')\n",
      "tensor([6, 2, 3, 5, 3, 8, 0, 2, 1, 1, 1, 1, 4, 2, 9, 7], device='cuda:0')\n",
      "tensor([2, 5, 1, 1, 2, 1, 9, 9, 9, 1, 0, 2, 0, 2, 1, 1], device='cuda:0')\n",
      "tensor([4, 6, 4, 1, 5, 4, 9, 9, 7, 1, 5, 6, 2, 2, 2, 8], device='cuda:0')\n",
      "tensor([0, 6, 9, 6, 3, 9, 7, 7, 1, 4, 8, 5, 3, 4, 3, 4], device='cuda:0')\n",
      "tensor([7, 7, 5, 0, 7, 4, 8, 8, 1, 5, 3, 9, 5, 9, 7, 6], device='cuda:0')\n",
      "tensor([9, 0, 3, 6, 3, 9, 8, 2, 2, 1, 2, 8, 6, 8, 5, 5], device='cuda:0')\n",
      "tensor([3, 9, 4, 9, 2, 5, 1, 5, 1, 4, 4, 1, 4, 6, 3, 3], device='cuda:0')\n",
      "tensor([9, 1, 2, 2, 3, 3, 0, 2, 9, 0, 0, 9, 9, 6, 0, 9], device='cuda:0')\n",
      "tensor([3, 7, 8, 4, 1, 9, 7, 7, 2, 7, 9, 9, 5, 9, 5, 1], device='cuda:0')\n",
      "tensor([1, 8, 7, 5, 1, 9, 5, 3, 5, 4, 9, 5, 9, 3, 1, 9], device='cuda:0')\n",
      "tensor([0, 9, 7, 5, 4, 9, 2, 0, 1, 0, 5, 1, 4, 9, 3, 3], device='cuda:0')\n",
      "tensor([6, 1, 5, 2, 5, 2, 2, 0, 3, 2, 6, 6, 0, 1, 8, 0], device='cuda:0')\n",
      "tensor([3, 0, 2, 5, 5, 7, 9, 5, 3, 0, 8, 9, 5, 0, 3, 2], device='cuda:0')\n",
      "tensor([5, 4, 0, 8, 8, 4, 5, 8, 8, 4, 5, 4, 8, 5, 4, 9], device='cuda:0')\n",
      "tensor([2, 2, 1, 2, 6, 8, 8, 7, 0, 3, 6, 6, 4, 3, 8, 8], device='cuda:0')\n",
      "tensor([7, 2, 2, 0, 0, 9, 3, 9, 9, 1, 9, 8, 6, 6, 4, 2], device='cuda:0')\n",
      "tensor([6, 9, 2, 8, 5, 4, 5, 7, 9, 4, 9, 2, 1, 8, 3, 4], device='cuda:0')\n",
      "tensor([0, 2, 8, 3, 9, 3, 4, 6, 5, 6, 2, 3, 9, 2, 6, 0], device='cuda:0')\n",
      "tensor([0, 6, 1, 2, 8, 7, 9, 8, 2, 0, 4, 7, 7, 5, 0, 5], device='cuda:0')\n",
      "tensor([6, 4, 6, 7, 4, 3, 0, 7, 5, 0, 7, 4, 2, 0, 8, 9], device='cuda:0')\n",
      "tensor([9, 4, 2, 4, 6, 7, 8, 7, 6, 9, 4, 1, 3, 7, 3, 0], device='cuda:0')\n",
      "tensor([8, 7, 7, 6, 1, 3, 9, 2, 2, 9, 2, 1, 8, 3, 2, 9], device='cuda:0')\n",
      "tensor([6, 8, 4, 0, 1, 2, 8, 4, 5, 2, 7, 8, 1, 1, 3, 0], device='cuda:0')\n",
      "tensor([3, 5, 7, 0, 3, 1, 9, 3, 6, 3, 1, 7, 7, 3, 0, 8], device='cuda:0')\n",
      "tensor([4, 8, 2, 6, 5, 2, 9, 7, 9, 9, 0, 9, 9, 6, 4, 2], device='cuda:0')\n",
      "tensor([9, 7, 2, 1, 1, 6, 7, 4, 7, 5, 9, 6, 8, 2, 1, 4], device='cuda:0')\n",
      "tensor([4, 5, 9, 6, 1, 3, 2, 5, 9, 9, 3, 6, 1, 1, 4, 6], device='cuda:0')\n",
      "tensor([9, 7, 2, 1, 5, 1, 4, 6, 3, 8, 1, 1, 0, 3, 1, 6], device='cuda:0')\n",
      "tensor([8, 4, 9, 0, 7, 3, 0, 4, 9, 0, 6, 6, 6, 3, 6, 7], device='cuda:0')\n",
      "tensor([7, 2, 8, 6, 0, 8, 3, 0, 2, 9, 8, 3, 2, 5, 3, 8], device='cuda:0')\n",
      "tensor([8, 0, 0, 1, 9, 5, 1, 3, 9, 6, 0, 1, 4, 1, 7, 1], device='cuda:0')\n",
      "tensor([2, 3, 7, 9, 7, 4, 9, 9, 3, 9, 2, 8, 2, 7, 1, 8], device='cuda:0')\n",
      "tensor([0, 9, 1, 0, 1, 7, 7, 9, 6, 9, 9, 9, 2, 1, 6, 1], device='cuda:0')\n",
      "tensor([3, 5, 2, 1, 9, 7, 6, 4, 5, 7, 6, 6, 9, 9, 6, 3], device='cuda:0')\n",
      "tensor([6, 2, 9, 8, 1, 2, 2, 5, 5, 2, 3, 7, 2, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 4, 5, 3, 8, 2, 8, 3, 5, 1, 7, 7, 1, 1, 2, 9], device='cuda:0')\n",
      "tensor([7, 8, 4, 0, 3, 0, 7, 8, 8, 4, 7, 7, 8, 5, 8, 6], device='cuda:0')\n",
      "tensor([9, 8, 1, 3, 8, 0, 3, 1, 7, 9, 5, 5, 1, 6, 5, 7], device='cuda:0')\n",
      "tensor([4, 9, 3, 5, 4, 7, 1, 2, 0, 8, 1, 6, 0, 7, 3, 4], device='cuda:0')\n",
      "tensor([7, 3, 9, 6, 0, 8, 6, 4, 8, 7, 7, 9, 3, 8, 6, 9], device='cuda:0')\n",
      "tensor([7, 2, 3, 4, 0, 2, 1, 8, 3, 5, 5, 7, 2, 4, 4, 7], device='cuda:0')\n",
      "tensor([2, 8, 3, 0, 8, 7, 8, 4, 0, 8, 4, 4, 5, 8, 5, 6], device='cuda:0')\n",
      "tensor([6, 3, 0, 9, 3, 2, 6, 8, 9, 3, 4, 9, 5, 8, 9, 1], device='cuda:0')\n",
      "tensor([2, 8, 8, 6, 8, 1, 3, 7, 9, 0, 1, 1, 9, 7, 0, 8], device='cuda:0')\n",
      "tensor([1, 7, 4, 5, 7, 1, 2, 1, 1, 3, 9, 6, 2, 1, 2, 8], device='cuda:0')\n",
      "tensor([8, 7, 6, 6, 9, 3, 7, 0, 5, 2, 3, 0, 5, 4, 3, 8], device='cuda:0')\n",
      "tensor([4, 6, 6, 2, 7, 9, 5, 1, 3, 2, 4, 3, 6, 1, 9, 4], device='cuda:0')\n",
      "tensor([4, 7, 6, 5, 4, 1, 9, 9, 2, 7, 8, 0, 1, 3, 6, 1], device='cuda:0')\n",
      "tensor([3, 4, 1, 1, 1, 5, 6, 0, 7, 0, 7, 2, 3, 2, 5, 2], device='cuda:0')\n",
      "tensor([2, 9, 4, 9, 8, 1, 2, 1, 6, 1, 2, 7, 4, 0, 0, 0], device='cuda:0')\n",
      "tensor([8, 2, 2, 9, 2, 2, 9, 9, 9, 2, 7, 5, 1, 3, 4, 9], device='cuda:0')\n",
      "tensor([4, 1, 8, 5, 6, 2, 8, 3, 1, 2, 8, 4, 9, 9, 3, 7], device='cuda:0')\n",
      "tensor([0, 7, 7, 2, 3, 2, 4, 0, 3, 9, 9, 8, 4, 1, 0, 6], device='cuda:0')\n",
      "tensor([0, 9, 6, 8, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5, 9, 4], device='cuda:0')\n",
      "tensor([2, 1, 9, 4, 3, 9, 6, 0, 4, 0, 6, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([5, 6, 7, 8, 9, 8, 3, 4, 7, 8, 6, 3, 4, 0, 9, 7], device='cuda:0')\n",
      "tensor([1, 9, 3, 8, 4, 7, 3, 0, 9, 1, 4, 5, 4, 6, 2, 0], device='cuda:0')\n",
      "tensor([6, 2, 1, 1, 1, 1, 7, 2, 4, 7, 5, 2, 9, 4, 5, 8], device='cuda:0')\n",
      "tensor([4, 2, 9, 7, 0, 0, 7, 5, 1, 1, 7, 6, 6, 6, 8, 2], device='cuda:0')\n",
      "tensor([2, 7, 7, 4, 0, 2, 4, 2, 1, 8, 9, 6, 1, 0, 5, 9], device='cuda:0')\n",
      "tensor([6, 9, 8, 0, 5, 0, 8, 3, 9, 6, 3, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 5, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 5, 6, 7, 8, 5, 4, 8, 7, 4, 7, 7, 3, 9, 8], device='cuda:0')\n",
      "tensor([8, 3, 1, 5, 8, 2, 7, 4, 2, 1, 5, 4, 5, 5, 8, 6], device='cuda:0')\n",
      "tensor([4, 4, 4, 1, 8, 7, 5, 5, 1, 8, 9, 1, 3, 6, 3, 3], device='cuda:0')\n",
      "tensor([2, 2, 6, 9, 9, 6, 5, 5, 3, 3, 8, 1, 6, 5, 6, 8], device='cuda:0')\n",
      "tensor([1, 9, 7, 6, 8, 3, 7, 4, 7, 0, 9, 0, 0, 3, 7, 9], device='cuda:0')\n",
      "tensor([3, 0, 2, 0, 1, 0, 1, 0, 4, 0, 1, 0, 4, 7, 9, 6], device='cuda:0')\n",
      "tensor([2, 6, 2, 2, 9, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5], device='cuda:0')\n",
      "tensor([6, 7, 8, 9, 8, 0, 5, 6, 6, 0, 8, 0, 2, 3, 7, 9], device='cuda:0')\n",
      "tensor([4, 7, 1, 9, 1, 7, 1, 4, 0, 0, 4, 1, 7, 5, 7, 1], device='cuda:0')\n",
      "tensor([3, 3, 3, 6, 6, 9, 7, 4, 3, 0, 2, 5, 2, 6, 0, 8], device='cuda:0')\n",
      "tensor([9, 4, 3, 5, 4, 8, 1, 5, 9, 0, 6, 4, 3, 6, 3, 3], device='cuda:0')\n",
      "tensor([8, 1, 4, 7, 5, 7, 2, 2, 0, 0, 1, 7, 7, 9, 5, 9], device='cuda:0')\n",
      "tensor([8, 9, 6, 8, 8, 2, 3, 6, 1, 2, 9, 8, 9, 5, 2, 6], device='cuda:0')\n",
      "tensor([2, 4, 8, 4, 6, 5, 0, 1, 5, 6, 7, 8, 9, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 2, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "tensor([9, 7, 4, 2, 0, 9, 0, 1, 5, 8, 8, 0, 2, 7, 8, 4], device='cuda:0')\n",
      "tensor([4, 6, 1, 0, 4, 5, 3, 9, 4, 2, 7, 5, 0, 1, 3, 2], device='cuda:0')\n",
      "tensor([9, 8, 6, 0, 1, 1, 8, 0, 4, 7, 7, 6, 3, 6, 0, 7], device='cuda:0')\n",
      "tensor([3, 5, 4, 2, 4, 1, 8, 3, 5, 6, 7, 0, 6, 7, 1, 2], device='cuda:0')\n",
      "tensor([5, 8, 1, 9, 3, 8, 2, 8, 7, 6, 7, 1, 4, 6, 2, 9], device='cuda:0')\n",
      "tensor([3, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 0], device='cuda:0')\n",
      "tensor([1, 2, 8, 9, 1, 4, 0, 9, 5, 0, 8, 0, 7, 7, 1, 1], device='cuda:0')\n",
      "tensor([2, 9, 3, 6, 7, 2, 3, 8, 1, 2, 9, 8, 8, 7, 1, 7], device='cuda:0')\n",
      "tensor([1, 1, 0, 3, 4, 2, 6, 4, 7, 4, 2, 7, 4, 9, 1, 0], device='cuda:0')\n",
      "tensor([6, 8, 5, 5, 5, 3, 5, 9, 7, 4, 8, 5, 9, 6, 9, 3], device='cuda:0')\n",
      "tensor([0, 3, 8, 9, 1, 8, 1, 6, 0, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([9, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 5, 6, 7, 8, 9, 3, 5, 3, 2, 9, 3, 2, 1, 4], device='cuda:0')\n",
      "tensor([5, 5, 3, 3, 2, 1, 3, 9, 7, 2, 8, 2, 8, 9, 1, 8], device='cuda:0')\n",
      "tensor([8, 7, 8, 1, 0, 0, 7, 2, 8, 7, 5, 0, 6, 1, 5, 7], device='cuda:0')\n",
      "tensor([4, 6, 1, 2, 5, 0, 7, 9, 9, 0, 3, 8, 4, 4, 8, 1], device='cuda:0')\n",
      "tensor([8, 6, 5, 9, 0, 0, 0, 3, 7, 1, 6, 4, 2, 6, 6, 0], device='cuda:0')\n",
      "tensor([4, 5, 4, 1, 3, 8, 6, 3, 9, 9, 5, 9, 3, 7, 8, 5], device='cuda:0')\n",
      "tensor([6, 4, 7, 6, 2, 2, 0, 9, 4, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 7, 5, 6, 7, 1, 2, 3, 4, 5, 2], device='cuda:0')\n",
      "tensor([8, 7, 1, 3, 2, 2, 0, 7, 5, 9, 9, 6, 0, 9, 4, 1], device='cuda:0')\n",
      "tensor([3, 2, 1, 2, 3, 8, 3, 2, 6, 5, 6, 8, 2, 7, 4, 8], device='cuda:0')\n",
      "tensor([1, 8, 0, 5, 3, 9, 4, 1, 9, 2, 1, 9, 6, 7, 9, 0], device='cuda:0')\n",
      "tensor([4, 6, 1, 7, 3, 8, 7, 2, 9, 6, 5, 8, 3, 9, 0, 5], device='cuda:0')\n",
      "tensor([7, 1, 6, 1, 0, 9, 3, 3, 4, 4, 0, 6, 2, 5, 4, 2], device='cuda:0')\n",
      "tensor([3, 4, 6, 0, 0, 2, 0, 1, 4, 5, 6, 9, 8, 9, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 7, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "tensor([9, 8, 7, 1, 3, 7, 5, 2, 8, 0, 7, 5, 9, 9, 0, 9], device='cuda:0')\n",
      "tensor([1, 1, 5, 8, 8, 6, 3, 2, 1, 8, 3, 2, 6, 5, 6, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 5, 3, 1, 9, 2, 1, 9, 6, 0, 4, 6, 1, 7], device='cuda:0')\n",
      "tensor([3, 8, 7, 2, 9, 6, 5, 8, 3, 5, 7, 1, 6, 1, 0, 9], device='cuda:0')\n",
      "tensor([6, 2, 5, 4, 2, 3, 4, 4, 6, 0, 0, 2, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 3, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "tensor([0, 1, 2, 8, 4, 5, 6, 7, 8, 9, 8, 6, 5, 0, 6, 8], device='cuda:0')\n",
      "tensor([9, 4, 1, 9, 3, 8, 0, 4, 8, 9, 1, 4, 0, 5, 5, 2], device='cuda:0')\n",
      "tensor([1, 5, 4, 0, 7, 6, 0, 1, 7, 0, 6, 8, 9, 5, 1, 7], device='cuda:0')\n",
      "tensor([9, 8, 6, 0, 8, 1, 7, 7, 1, 3, 2, 3, 1, 4, 2, 0], device='cuda:0')\n",
      "tensor([0, 7, 8, 4, 6, 4, 9, 3, 8, 4, 7, 2, 3, 6, 3, 6], device='cuda:0')\n",
      "tensor([9, 6, 3, 2, 2, 4, 6, 9, 0, 2, 5, 5, 1, 5, 8, 9], device='cuda:0')\n",
      "tensor([7, 8, 7, 2, 2, 5, 7, 9, 8, 2, 1, 3, 1, 3, 0, 1], device='cuda:0')\n",
      "tensor([2, 8, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 6, 5], device='cuda:0')\n",
      "tensor([3, 0, 7, 0, 4, 1, 4, 3, 6, 7, 2, 3, 1, 2, 1, 2], device='cuda:0')\n",
      "tensor([9, 6, 0, 1, 3, 0, 2, 7, 5, 7, 6, 2, 9, 1, 9, 0], device='cuda:0')\n",
      "tensor([6, 0, 6, 0, 2, 0, 6, 1, 5, 8, 4, 3, 0, 1, 5, 4], device='cuda:0')\n",
      "tensor([4, 8, 5, 7, 5, 7, 8, 3, 4, 8, 8, 5, 2, 9, 7, 1], device='cuda:0')\n",
      "tensor([3, 8, 1, 0, 7, 5, 3, 6, 9, 4, 7, 7, 9, 9, 3, 4], device='cuda:0')\n",
      "tensor([4, 3, 8, 6, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 8, 3, 9, 5, 5, 2, 6, 8, 4, 9, 1, 7], device='cuda:0')\n",
      "tensor([1, 2, 3, 5, 9, 6, 9, 1, 1, 1, 2, 9, 5, 6, 8, 1], device='cuda:0')\n",
      "tensor([2, 0, 7, 7, 5, 8, 2, 9, 8, 9, 0, 4, 6, 7, 1, 3], device='cuda:0')\n",
      "tensor([4, 5, 6, 0, 3, 6, 8, 7, 0, 4, 2, 7, 4, 7, 5, 4], device='cuda:0')\n",
      "tensor([3, 4, 2, 8, 1, 5, 1, 2, 0, 2, 5, 6, 4, 3, 0, 0], device='cuda:0')\n",
      "tensor([0, 3, 3, 5, 7, 0, 6, 4, 8, 8, 6, 3, 4, 6, 9, 9], device='cuda:0')\n",
      "tensor([8, 2, 7, 7, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 2, 1, 7, 2, 5, 0, 8, 0, 2, 7, 8, 8, 3, 6, 0], device='cuda:0')\n",
      "tensor([2, 7, 6, 6, 1, 2, 8, 8, 7, 7, 4, 7, 7, 3, 7, 4], device='cuda:0')\n",
      "tensor([5, 4, 3, 3, 8, 4, 1, 1, 9, 7, 4, 3, 7, 3, 3, 0], device='cuda:0')\n",
      "tensor([2, 5, 5, 6, 6, 3, 5, 2, 5, 9, 9, 8, 4, 1, 0, 6], device='cuda:0')\n",
      "tensor([6, 9, 6, 8, 8, 5, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5], device='cuda:0')\n",
      "tensor([9, 4, 2, 1, 9, 2, 9, 2, 0, 6, 0, 4, 0, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 7, 8, 9, 0, 1, 2, 3, 7, 8, 9, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 7, 8, 9, 7, 3, 0, 3, 1, 8, 7, 6, 4, 0, 2, 6], device='cuda:0')\n",
      "tensor([8, 3, 2, 8, 1, 2, 0, 7, 1, 0, 4, 4, 5, 8, 0, 6], device='cuda:0')\n",
      "tensor([2, 3, 1, 5, 1, 8, 5, 9, 4, 0, 7, 5, 8, 8, 3, 8], device='cuda:0')\n",
      "tensor([9, 2, 6, 2, 5, 3, 1, 7, 3, 0, 1, 9, 9, 6, 0, 3], device='cuda:0')\n",
      "tensor([9, 2, 8, 1, 4, 3, 5, 2, 9, 2, 5, 8, 9, 5, 0, 1], device='cuda:0')\n",
      "tensor([2, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([5, 1, 0, 4, 5, 6, 6, 3, 4, 4, 2, 9, 1, 0, 6, 4], device='cuda:0')\n",
      "tensor([9, 7, 2, 3, 3, 9, 2, 0, 9, 3, 3, 9, 1, 5, 6, 3], device='cuda:0')\n",
      "tensor([7, 7, 8, 4, 0, 2, 4, 0, 2, 4, 7, 8, 0, 7, 5, 6], device='cuda:0')\n",
      "tensor([9, 3, 2, 8, 6, 7, 5, 7, 5, 1, 0, 8, 1, 6, 7, 2], device='cuda:0')\n",
      "tensor([9, 7, 9, 5, 8, 6, 2, 6, 2, 8, 1, 7, 5, 7, 1, 1], device='cuda:0')\n",
      "tensor([3, 8, 4, 9, 1, 8, 6, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 8, 1, 7, 8, 9], device='cuda:0')\n",
      "tensor([9, 8, 9, 8, 4, 1, 7, 7, 3, 3, 7, 6, 6, 6, 1, 9], device='cuda:0')\n",
      "tensor([0, 1, 7, 6, 3, 2, 1, 7, 1, 3, 9, 1, 7, 6, 8, 4], device='cuda:0')\n",
      "tensor([1, 4, 3, 6, 9, 6, 1, 4, 4, 7, 2, 4, 4, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 3, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 7, 8, 1, 3, 5, 1, 7, 7, 2, 1, 4, 8], device='cuda:0')\n",
      "tensor([3, 4, 4, 3, 9, 7, 4, 1, 2, 3, 4, 9, 1, 6, 0, 1], device='cuda:0')\n",
      "tensor([0, 0, 2, 9, 7, 1, 1, 6, 0, 4, 7, 3, 6, 8, 0, 3], device='cuda:0')\n",
      "tensor([7, 4, 0, 6, 9, 2, 6, 5, 8, 6, 9, 0, 4, 0, 6, 6], device='cuda:0')\n",
      "tensor([9, 2, 0, 9, 5, 1, 3, 7, 6, 9, 3, 0, 2, 2, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 2, 1, 7, 2], device='cuda:0')\n",
      "tensor([5, 0, 8, 0, 2, 7, 8, 8, 3, 0, 6, 0, 2, 7, 6, 6], device='cuda:0')\n",
      "tensor([1, 2, 8, 8, 7, 7, 4, 7, 7, 3, 7, 4, 5, 4, 3, 3], device='cuda:0')\n",
      "tensor([8, 4, 5, 4, 1, 1, 9, 7, 4, 3, 7, 3, 3, 0, 2, 5], device='cuda:0')\n",
      "tensor([5, 6, 3, 1, 5, 2, 5, 9, 9, 8, 4, 1, 0, 6, 0, 9], device='cuda:0')\n",
      "tensor([6, 8, 8, 5, 6, 1, 1, 9, 8, 9, 2, 3, 5, 5, 9, 4], device='cuda:0')\n",
      "tensor([2, 1, 9, 4, 9, 1, 3, 9, 2, 0, 6, 0, 4, 0, 6, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 8, 0], device='cuda:0')\n",
      "tensor([7, 1, 0, 7, 5, 5, 6, 9, 0, 1, 0, 0, 8, 3, 4, 3], device='cuda:0')\n",
      "tensor([1, 5, 0, 0, 9, 5, 3, 4, 9, 3, 7, 6, 9, 2, 4, 5], device='cuda:0')\n",
      "tensor([7, 2, 6, 4, 9, 4, 9, 4, 1, 2, 2, 5, 8, 1, 3, 2], device='cuda:0')\n",
      "tensor([9, 4, 3, 8, 2, 2, 1, 2, 8, 6, 5, 1, 6, 7, 2, 1], device='cuda:0')\n",
      "tensor([3, 9, 3, 8, 7, 5, 7, 0, 7, 4, 8, 8, 5, 0, 6, 6], device='cuda:0')\n",
      "tensor([3, 7, 6, 9, 9, 4, 8, 4, 1, 0, 6, 6, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 4, 0, 4, 0, 1], device='cuda:0')\n",
      "tensor([7, 9, 5, 1, 4, 2, 8, 9, 4, 3, 7, 8, 2, 4, 4, 3], device='cuda:0')\n",
      "tensor([3, 6, 9, 9, 5, 8, 6, 7, 0, 6, 8, 2, 6, 3, 9, 3], device='cuda:0')\n",
      "tensor([2, 8, 6, 1, 7, 4, 8, 8, 9, 0, 3, 3, 9, 0, 5, 2], device='cuda:0')\n",
      "tensor([9, 4, 1, 0, 3, 7, 5, 8, 7, 7, 8, 2, 9, 7, 1, 2], device='cuda:0')\n",
      "tensor([6, 4, 2, 5, 2, 3, 6, 6, 5, 0, 0, 2, 8, 1, 6, 1], device='cuda:0')\n",
      "tensor([0, 4, 3, 1, 6, 1, 9, 0, 1, 4, 5, 6, 7, 8, 9, 1], device='cuda:0')\n",
      "tensor([2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "tensor([8, 4, 0, 0, 7, 2, 4, 3, 8, 6, 6, 3, 2, 6, 3, 3], device='cuda:0')\n",
      "tensor([0, 1, 4, 7, 8, 0, 3, 1, 9, 0, 1, 9, 1, 2, 7, 0], device='cuda:0')\n",
      "tensor([1, 5, 8, 2, 9, 2, 7, 6, 5, 5, 9, 9, 8, 2, 9, 1], device='cuda:0')\n",
      "tensor([3, 2, 3, 4, 3, 1, 9, 0, 9, 3, 6, 8, 7, 0, 1, 0], device='cuda:0')\n",
      "tensor([5, 8, 2, 7, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 1, 7, 4, 8, 1, 5, 6, 5, 7, 2, 8, 6, 3], device='cuda:0')\n",
      "tensor([3, 8, 6, 5, 4, 0, 9, 1, 7, 2, 9, 1, 5, 1, 3, 2], device='cuda:0')\n",
      "tensor([2, 3, 0, 6, 4, 3, 7, 6, 9, 0, 4, 8, 1, 4, 0, 6], device='cuda:0')\n",
      "tensor([1, 2, 6, 9, 2, 2, 3, 5, 5, 1, 0, 7, 7, 9, 6, 2], device='cuda:0')\n",
      "tensor([9, 4, 7, 0, 2, 3, 4, 0, 0, 8, 8, 8, 5, 1, 3, 7], device='cuda:0')\n",
      "tensor([4, 9, 8, 8, 9, 0, 9, 8, 9, 0, 2, 6, 5, 6, 7, 4], device='cuda:0')\n",
      "tensor([7, 5, 4, 1, 3, 5, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 6, 0, 1, 2, 4, 5, 6, 7, 8, 1, 7, 2, 4, 1, 4], device='cuda:0')\n",
      "tensor([1, 4, 9, 6, 8, 4, 5, 3, 7, 8, 8, 3, 3, 5, 6, 7], device='cuda:0')\n",
      "tensor([0, 6, 1, 6, 8, 7, 0, 1, 5, 0, 8, 5, 0, 1, 5, 8], device='cuda:0')\n",
      "tensor([4, 2, 3, 9, 7, 6, 9, 1, 9, 0, 6, 7, 1, 2, 3, 9], device='cuda:0')\n",
      "tensor([2, 4, 5, 5, 3, 7, 5, 3, 1, 8, 2, 2, 3, 0, 2, 9], device='cuda:0')\n",
      "tensor([4, 9, 7, 0, 2, 7, 4, 9, 9, 2, 5, 9, 8, 3, 8, 6], device='cuda:0')\n",
      "tensor([7, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')\n",
      "tensor([0, 0, 7, 2, 6, 5, 5, 3, 7, 8, 6, 6, 6, 6, 4, 3], device='cuda:0')\n",
      "tensor([8, 8, 3, 0, 1, 9, 0, 5, 4, 1, 9, 1, 2, 7, 0, 1], device='cuda:0')\n",
      "tensor([3, 8, 2, 9, 2, 7, 4, 2, 6, 5, 5, 9, 9, 1, 1, 5], device='cuda:0')\n",
      "tensor([7, 6, 8, 2, 9, 4, 3, 1, 9, 0, 9, 3, 6, 8, 7, 0], device='cuda:0')\n",
      "tensor([1, 0, 5, 8, 2, 7, 7, 0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "tensor([9, 0, 1, 2, 3, 4, 5, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 2, 1, 2, 1, 3, 9, 9, 8, 5, 3, 7, 0, 7], device='cuda:0')\n",
      "tensor([7, 5, 7, 9, 9, 4, 7, 0, 3, 4, 1, 5, 8, 1, 4, 8], device='cuda:0')\n",
      "tensor([4, 1, 8, 6, 6, 4, 6, 0, 5, 5, 3, 3, 5, 7, 2, 5], device='cuda:0')\n",
      "tensor([9, 6, 9, 2, 6, 2, 1, 2, 0, 8, 3, 8, 3, 0, 8, 7], device='cuda:0')\n",
      "tensor([4, 9, 5, 0, 9, 7, 0, 0, 4, 6, 0, 9, 1, 6, 2, 7], device='cuda:0')\n",
      "tensor([6, 8, 3, 5, 2, 1, 8, 3, 8, 6, 1, 0, 2, 1, 4, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 4, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 6, 4], device='cuda:0')\n",
      "tensor([7, 6, 2, 3, 4, 8, 7, 8, 6, 9, 8, 3, 2, 2, 8, 4], device='cuda:0')\n",
      "tensor([8, 5, 6, 5, 0, 2, 0, 1, 1, 2, 9, 6, 8, 2, 1, 0], device='cuda:0')\n",
      "tensor([6, 5, 2, 9, 7, 5, 3, 9, 3, 7, 1, 8, 3, 8, 1, 9], device='cuda:0')\n",
      "tensor([5, 5, 0, 1, 1, 9, 8, 2, 6, 0, 4, 5, 0, 3, 1, 8], device='cuda:0')\n",
      "tensor([6, 7, 5, 9, 9, 3, 0, 3, 1, 4, 4, 0, 4, 9, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 5, 6, 7, 8, 0, 1, 2, 3, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 6, 6, 7, 8, 9, 9, 7, 0, 9, 0, 1, 5, 8], device='cuda:0')\n",
      "tensor([8, 0, 9, 3, 2, 7, 8, 4, 6, 1, 0, 4, 9, 4, 2, 0], device='cuda:0')\n",
      "tensor([5, 0, 1, 6, 9, 3, 2, 9, 1, 6, 0, 1, 1, 8, 7, 7], device='cuda:0')\n",
      "tensor([6, 3, 6, 0, 7, 2, 4, 1, 7, 0, 6, 7, 1, 2, 5, 8], device='cuda:0')\n",
      "tensor([1, 5, 2, 8, 7, 6, 8, 7, 1, 6, 2, 9, 3, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "tensor([9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 9, 5, 7, 0], device='cuda:0')\n",
      "tensor([3, 1, 6, 8, 4, 1, 5, 6, 4, 2, 7, 8, 1, 3, 4, 3], device='cuda:0')\n",
      "tensor([4, 7, 2, 0, 5, 0, 1, 9, 2, 3, 2, 3, 5, 5, 7, 8], device='cuda:0')\n",
      "tensor([4, 9, 9, 7, 1, 1, 9, 0, 7, 8, 3, 4, 8, 6, 3, 8], device='cuda:0')\n",
      "tensor([0, 9, 6, 2, 8, 0, 1, 0, 6, 2, 3, 8, 9, 0, 7, 2], device='cuda:0')\n",
      "tensor([3, 4, 5, 5, 2, 8, 5, 4, 6, 6, 6, 7, 9, 1, 8, 2], device='cuda:0')\n",
      "tensor([1, 5, 3, 4, 7, 9, 4, 0, 0, 0, 1, 2, 3, 4, 8, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2], device='cuda:0')\n",
      "tensor([3, 4, 5, 6, 9, 0, 1, 3, 1, 5, 1, 2, 4, 9, 2, 4], device='cuda:0')\n",
      "tensor([6, 8, 0, 1, 1, 9, 2, 6, 6, 8, 7, 4, 2, 9, 7, 0], device='cuda:0')\n",
      "tensor([2, 1, 0, 3, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 8, 6, 5, 9, 7, 0, 2, 3, 4, 3, 8, 5, 1], device='cuda:0')\n",
      "tensor([5, 2, 3, 0, 1, 2, 1, 3, 2, 6, 5, 3, 0, 7, 2, 7], device='cuda:0')\n",
      "tensor([4, 6, 4, 0, 5, 9, 9, 8, 9, 5, 3, 1, 7, 4, 7, 6], device='cuda:0')\n",
      "tensor([5, 4, 0, 0, 6, 6, 2, 0, 6, 3, 7, 7, 4, 4, 3, 9], device='cuda:0')\n",
      "tensor([2, 8, 9, 6, 0, 9, 5, 3, 8, 8, 7, 1, 4, 0, 4, 8], device='cuda:0')\n",
      "tensor([5, 2, 3, 9, 0, 1, 9, 1, 5, 1, 7, 4, 8, 6, 2, 1], device='cuda:0')\n",
      "tensor([6, 8, 8, 2, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([6, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8, 9, 1, 4, 5, 3], device='cuda:0')\n",
      "tensor([3, 0, 9, 5, 4, 8, 0, 8, 4, 6, 7, 0, 7, 7, 1, 6], device='cuda:0')\n",
      "tensor([9, 1, 3, 6, 2, 3, 8, 2, 3, 8, 9, 5, 8, 8, 7, 1], device='cuda:0')\n",
      "tensor([7, 1, 1, 0, 3, 4, 2, 6, 4, 7, 4, 2, 2, 4, 2, 9], device='cuda:0')\n",
      "tensor([2, 7, 9, 2, 1, 6, 6, 5, 3, 4, 8, 5, 7, 6, 9, 0], device='cuda:0')\n",
      "tensor([6, 3, 0, 8, 1, 6, 0, 0, 1, 2, 3, 4, 5, 6, 7, 0], device='cuda:0')\n",
      "tensor([1, 4, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 7, 2, 5, 1], device='cuda:0')\n",
      "tensor([6, 4, 3, 9, 9, 0, 9, 7, 1, 6, 4, 3, 6, 2, 0, 9], device='cuda:0')\n",
      "tensor([8, 6, 5, 7, 0, 0, 1, 7, 4, 3, 2, 4, 1, 3, 7, 6], device='cuda:0')\n",
      "tensor([4, 7, 7, 7, 9, 8, 4, 3, 6, 2, 8, 3, 5, 8, 0, 5], device='cuda:0')\n",
      "tensor([4, 7, 1, 3, 1, 7, 9, 6, 2, 0, 9, 1, 7, 3, 3, 9], device='cuda:0')\n",
      "tensor([1, 6, 4, 3, 9, 8, 2, 1, 8, 6, 4, 1, 5, 5, 6, 5], device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5], device='cuda:0')\n",
      "tensor([6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 9], device='cuda:0')\n",
      "tensor([7, 0, 2, 3, 4, 3, 8, 5, 1, 3, 0, 1, 2, 1, 3, 2], device='cuda:0')\n",
      "tensor([0, 7, 2, 6, 4, 0, 3, 9, 9, 8, 9, 5, 3, 1, 7, 4], device='cuda:0')\n",
      "tensor([7, 0, 0, 6, 6, 6, 3, 3, 9, 2, 6, 9, 8, 7, 1, 9], device='cuda:0')\n",
      "tensor([0, 4, 8, 5, 2, 3, 9, 0, 1, 9, 1, 5, 1, 7, 6, 1], device='cuda:0')\n",
      "tensor([2, 1, 6, 8, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 5, 6, 7, 8, 1], device='cuda:0')\n",
      "tensor([0, 4, 5, 6, 6, 3, 4, 4, 3, 8, 1, 0, 6, 4, 9, 7], device='cuda:0')\n",
      "tensor([2, 9, 2, 0, 9, 3, 3, 9, 1, 5, 2, 3, 1, 6, 7, 3], device='cuda:0')\n",
      "tensor([7, 8, 4, 0, 2, 4, 0, 2, 4, 7, 8, 0, 7, 0, 6, 9], device='cuda:0')\n",
      "tensor([3, 2, 4, 8, 6, 0, 5, 7, 5, 1, 0, 8, 1, 6, 7, 2], device='cuda:0')\n",
      "tensor([9, 7, 9, 5, 6, 5, 2, 6, 2, 8, 1, 7, 5, 5, 7, 3], device='cuda:0')\n",
      "tensor([5, 0, 1, 1, 3, 8, 4, 9, 4, 5, 1, 8, 6, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
      "tensor([7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 3], device='cuda:0')\n",
      "tensor([2, 9, 3, 2, 1, 4, 5, 5, 2, 3, 2, 1, 3, 9, 7, 2], device='cuda:0')\n",
      "tensor([1, 2, 8, 9, 1, 8, 8, 7, 8, 1, 0, 0, 6, 7, 7, 8], device='cuda:0')\n",
      "tensor([7, 5, 0, 6, 1, 5, 7, 4, 6, 1, 2, 5, 0, 7, 9, 9], device='cuda:0')\n",
      "tensor([0, 3, 4, 4, 8, 4, 1, 8, 6, 5, 9, 0, 0, 0, 3, 7], device='cuda:0')\n",
      "tensor([1, 6, 4, 6, 0, 4, 5, 4, 1, 3, 8, 6, 3, 9, 9, 5], device='cuda:0')\n",
      "tensor([9, 3, 7, 8, 5, 6, 4, 7, 6, 2, 2, 0, 9, 4, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 6, 4, 2, 6], device='cuda:0')\n",
      "tensor([4, 7, 5, 5, 4, 7, 2, 9, 3, 9, 3, 8, 2, 0, 9, 5], device='cuda:0')\n",
      "tensor([6, 0, 1, 0, 6, 5, 3, 5, 3, 8, 0, 0, 3, 4, 1, 6], device='cuda:0')\n",
      "tensor([3, 0, 8, 3, 0, 6, 2, 7, 8, 1, 7, 1, 3, 8, 5, 4], device='cuda:0')\n",
      "tensor([2, 0, 9, 7, 6, 7, 4, 1, 6, 2, 6, 7, 1, 9, 8, 0], device='cuda:0')\n",
      "tensor([6, 9, 4, 9, 9, 6, 2, 3, 7, 1, 9, 2, 2, 5, 3, 7], device='cuda:0')\n",
      "tensor([8, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1, 2, 3, 4, 7, 8], device='cuda:0')\n",
      "tensor([9, 0, 1, 7, 8, 9, 8, 9, 2, 6, 1, 3, 5, 4, 8, 2], device='cuda:0')\n",
      "tensor([6, 4, 3, 4, 5, 9, 2, 0, 3, 9, 4, 9, 7, 3, 8, 7], device='cuda:0')\n",
      "tensor([4, 4, 9, 8, 5, 8, 2, 6, 6, 2, 3, 1, 3, 2, 7, 3], device='cuda:0')\n",
      "tensor([1, 9, 0, 1, 1, 3, 5, 0, 7, 8, 1, 5, 1, 4, 6, 0], device='cuda:0')\n",
      "tensor([0, 4, 9, 1, 6, 6, 9, 0, 7, 6, 1, 1, 0, 1, 2, 3], device='cuda:0')\n",
      "tensor([4, 3, 2, 3, 4, 5, 6, 2, 0, 1, 2, 2, 8, 6, 2, 9], device='cuda:0')\n",
      "tensor([2, 1, 9, 3, 9, 6, 1, 7, 2, 4, 4, 5, 7, 0, 0, 1], device='cuda:0')\n",
      "tensor([6, 6, 8, 2, 7, 7, 2, 4, 2, 1, 6, 1, 0, 6, 9, 8], device='cuda:0')\n",
      "tensor([3, 9, 6, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1], device='cuda:0')\n",
      "tensor([2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 9, 1, 6, 8, 9, 9, 0, 1, 2, 4, 4, 3, 7, 4, 4], device='cuda:0')\n",
      "tensor([4, 0, 3, 8, 7, 5, 8, 2, 1, 7, 5, 3, 8, 5, 2, 5], device='cuda:0')\n",
      "tensor([1, 1, 6, 2, 1, 3, 8, 6, 4, 2, 6, 2, 5, 5, 0, 2], device='cuda:0')\n",
      "tensor([8, 0, 6, 8, 1, 7, 9, 1, 9, 2, 6, 7, 6, 6, 8, 7], device='cuda:0')\n",
      "tensor([4, 9, 2, 1, 3, 3, 0, 5, 5, 8, 0, 3, 7, 9, 7, 0], device='cuda:0')\n",
      "tensor([2, 7, 9, 1, 7, 8, 0, 3, 5, 3, 6, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 7, 8, 9, 6, 4, 2, 6, 4, 7, 8, 9, 2], device='cuda:0')\n",
      "tensor([9, 3, 9, 3, 0, 0, 1, 0, 4, 2, 6, 3, 5, 3, 0, 3], device='cuda:0')\n",
      "tensor([4, 1, 5, 3, 0, 8, 3, 0, 6, 1, 7, 8, 0, 9, 2, 6], device='cuda:0')\n",
      "tensor([7, 1, 9, 6, 9, 4, 9, 9, 6, 7, 1, 2, 5, 3, 7, 8], device='cuda:0')\n",
      "tensor([0, 1, 2, 4, 5, 6, 7, 8, 9, 0, 1, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 0, 1, 3, 4, 7, 8, 9, 7, 5, 5, 1, 9, 9, 7, 1], device='cuda:0')\n",
      "tensor([0, 0, 5, 9, 7, 1, 7, 2, 2, 3, 6, 8, 3, 2, 0, 0], device='cuda:0')\n",
      "tensor([6, 1, 7, 5, 8, 6, 2, 9, 4, 8, 8, 7, 1, 0, 8, 7], device='cuda:0')\n",
      "tensor([7, 5, 8, 5, 3, 4, 6, 1, 1, 5, 5, 0, 7, 2, 3, 6], device='cuda:0')\n",
      "tensor([4, 1, 2, 4, 1, 5, 4, 2, 0, 4, 8, 6, 1, 9, 0, 2], device='cuda:0')\n",
      "tensor([5, 6, 9, 3, 6, 3, 6, 0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
      "tensor([9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 5], device='cuda:0')\n",
      "tensor([6, 7, 8, 1, 0, 9, 5, 7, 5, 1, 8, 6, 9, 0, 4, 1], device='cuda:0')\n",
      "tensor([9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7, 8, 2, 5, 9], device='cuda:0')\n",
      "tensor([6, 0, 6, 5, 5, 3, 3, 3, 9, 8, 1, 1, 0, 6, 1, 0], device='cuda:0')\n",
      "tensor([0, 6, 2, 1, 1, 3, 2, 7, 7, 8, 8, 7, 8, 4, 6, 0], device='cuda:0')\n",
      "tensor([2, 0, 7, 0, 3, 6, 8, 7, 1, 5, 9, 9, 3, 7, 2, 4], device='cuda:0')\n",
      "tensor([9, 4, 3, 6, 2, 2, 5, 3, 2, 5, 5, 9, 4, 1, 7, 2], device='cuda:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5], device='cuda:0')\n",
      "tensor([6, 7, 8, 9, 0, 1, 2, 3, 1, 8, 6, 7, 8, 9, 1, 0], device='cuda:0')\n",
      "tensor([1, 2, 7, 5, 3, 4, 4, 0, 0, 6, 9, 6, 6, 5, 7, 2], device='cuda:0')\n",
      "tensor([3, 4, 4, 9, 1, 4, 0, 7, 9, 5, 7, 2, 3, 1, 4, 4], device='cuda:0')\n",
      "tensor([0, 9, 9, 6, 1, 8, 3, 3, 7, 3, 9, 8, 8, 4, 7, 7], device='cuda:0')\n",
      "tensor([6, 2, 1, 9, 8, 7, 8, 8, 7, 2, 2, 3, 9, 3, 3, 5], device='cuda:0')\n",
      "tensor([5, 0, 7, 4, 5, 6, 5, 1, 4, 1, 1, 2, 8, 2, 6, 1], device='cuda:0')\n",
      "tensor([5, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4], device='cuda:0')\n",
      "tensor([5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 8, 0], device='cuda:0')\n",
      "tensor([6, 0, 8, 2, 3, 7, 9, 4, 7, 1, 9, 7, 7, 1, 4, 0], device='cuda:0')\n",
      "tensor([0, 1, 7, 5, 7, 1, 3, 3, 3, 1, 6, 9, 7, 1, 3, 0], device='cuda:0')\n",
      "tensor([7, 6, 0, 8, 9, 4, 3, 5, 4, 8, 1, 5, 9, 0, 6, 3], device='cuda:0')\n",
      "tensor([3, 8, 1, 4, 7, 5, 2, 0, 0, 1, 7, 8, 9, 6, 8, 8], device='cuda:0')\n",
      "tensor([2, 3, 5, 1, 8, 9, 5, 2, 0, 1, 2, 3, 4, 5, 6, 7], device='cuda:0')\n",
      "tensor([8, 9, 0, 1, 3, 3, 4, 5, 6, 7, 8, 9, 0, 1, 3, 3], device='cuda:0')\n",
      "tensor([4, 6, 6, 7, 8, 9, 7, 4, 6, 1, 4, 0, 9, 9, 8, 7], device='cuda:0')\n",
      "tensor([8, 2, 7, 5, 8, 6, 3, 2, 2, 0, 5, 8, 6, 0, 3, 8], device='cuda:0')\n",
      "tensor([1, 0, 3, 0, 4, 7, 4, 9, 5, 9, 0, 7, 1, 7, 1, 6], device='cuda:0')\n",
      "tensor([6, 0, 6, 5, 8, 7, 6, 4, 9, 9, 5, 3, 7, 4, 3, 0], device='cuda:0')\n",
      "tensor([4, 6, 6, 1, 1, 3, 2, 1, 0, 0, 1, 2, 3, 4, 7, 8], device='cuda:0')\n",
      "tensor([4, 0, 1, 8, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7], device='cuda:0')\n",
      "tensor([8, 9, 0, 8, 3, 9, 5, 5, 2, 6, 8, 4, 1, 7, 1, 3], device='cuda:0')\n",
      "tensor([3, 5, 6, 9, 1, 1, 1, 2, 1, 2, 0, 7, 7, 5, 8, 2], device='cuda:0')\n",
      "tensor([9, 8, 8, 7, 3, 4, 6, 8, 7, 0, 4, 2, 7, 7, 5, 4], device='cuda:0')\n",
      "tensor([3, 4, 2, 8, 1, 5, 1, 2, 2, 3, 3, 5, 7, 0, 6, 8], device='cuda:0')\n",
      "tensor([6, 3, 9, 9, 8, 2, 7, 7, 1, 0, 1, 7, 8, 9, 0, 1], device='cuda:0')\n",
      "tensor([0, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 7, 8, 9, 7], device='cuda:0')\n",
      "tensor([8, 6, 4, 1, 9, 3, 8, 4, 4, 7, 0, 1, 9, 2, 8, 7], device='cuda:0')\n",
      "tensor([8, 2, 6, 0, 6, 5, 3, 3, 8, 9, 1, 4, 0, 6, 1, 0], device='cuda:0')\n",
      "tensor([0, 6, 2, 1, 1, 7, 7, 8, 4, 6, 0, 7, 0, 3, 6, 8], device='cuda:0')\n",
      "tensor([7, 1, 5, 2, 4, 9, 4, 3, 6, 4, 1, 7, 3, 6, 5, 0], device='cuda:0')\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9699"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FFNN(torch.nn.Module):\n",
    "    def __init__(self, in_features, num_classes, lr=0.001):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=in_features, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=64, out_features=num_classes)\n",
    "        ).to(device)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optim = torch.optim.Adam(self.layers.parameters(), lr=lr)\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x.flatten(start_dim=1))\n",
    "\n",
    "    def train(self, train_dataloader, epochs=1, val_dataloader=None):\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)):\n",
    "\n",
    "            for inputs, targets in train_dataloader:\n",
    "                logits = self.forward(inputs)\n",
    "\n",
    "                loss = self.criterion(logits, targets)\n",
    "                loss.backward()\n",
    "\n",
    "                self.optim.step()\n",
    "                self.optim.zero_grad()\n",
    "\n",
    "            if val_dataloader is not None:\n",
    "                acc = self.eval(val_dataloader)\n",
    "                print(f\"Epoch {epoch} validation accuracy: {acc}\")\n",
    "\n",
    "    def eval(self, test_dataloader):\n",
    "        \n",
    "        total_acc = 0\n",
    "\n",
    "        for input_batch, label_batch in test_dataloader:\n",
    "            # Get predictions\n",
    "            outs = self(input_batch)\n",
    "\n",
    "            # Remember, outs are probabilities (so there's 10 for each input)\n",
    "            # The classification the network wants to assign, must therefore be the probability with the larget value\n",
    "            # We find that using argmax (dim=1, because dim=0 would be across batch dimension)\n",
    "            classifications = torch.argmax(outs, dim=1)\n",
    "            total_acc += (classifications == label_batch).sum().item()\n",
    "\n",
    "        total_acc = total_acc / len(test_dataloader.dataset)\n",
    "\n",
    "        return total_acc\n",
    "    \n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "print(next(iter(train_dataloader))[0].shape)\n",
    "\n",
    "model = FFNN(in_features=28*28,num_classes=10, lr=0.001)\n",
    "model.train(train_dataloader, epochs=5)\n",
    "model.eval(test_dataloader)\n",
    "\n",
    "# # summary(model, (3, 64, 64))\n",
    "# model.forward_checker(torch.zeros(16, 3, 64, 64))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show output of each convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "elif dataset == 'mnist':\n",
    "    train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Get indices of 10 different classes in the dataset\n",
    "sampled_indices = [np.random.choice(np.where(np.array(train_set.targets) == i)[0]) for i in range(10)]\n",
    "\n",
    "examples = train_set.data[sampled_indices]\n",
    "print(examples.shape)\n",
    "# # Get one example from each class\n",
    "# examples = get_examples_by_class(train_set)\n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# TODO: Use this plotting code above\n",
    "for i in range(10):\n",
    "    img = examples[i]\n",
    "    if dataset == 'mnist':\n",
    "        img = img.squeeze(0)  # Remove the channel dimension for MNIST\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "    else:\n",
    "        img = img.numpy().transpose((1, 2, 0))  # Convert to HWC format for CIFAR-10\n",
    "        axes[i].imshow(img)\n",
    "    axes[i].set_title(f'Class {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming that `model` is already defined as in your code\n",
    "# and contains the layers you provided.\n",
    "\n",
    "def visualize_kernel_output(model, image):\n",
    "\n",
    "    image = image.unsqueeze(0)  # Add batch dimension: (1, 1, H, W)\n",
    "    outputs = []\n",
    "\n",
    "    for layer in model.layers:\n",
    "        kernel_weights = layer.weight.detach().cpu()\n",
    "        print(f\"Kernel weights shape: {kernel_weights.shape}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs.append(layer(image))\n",
    "            \n",
    "\n",
    "\n",
    "    # Get the first convolutional layer\n",
    "    first_conv_layer = model.layers[0]  # First layer is Conv2d\n",
    "    \n",
    "    # Get the weights of the first kernel in the first conv layer\n",
    "    first_kernel_weights = first_conv_layer.weight[0].detach().cpu()  # Shape: (out_channels, in_channels, kernel_size, kernel_size)\n",
    "    \n",
    "    print(f\"First kernel weights shape: {first_kernel_weights.shape}\")\n",
    "    \n",
    "    # Pass the image through the first convolutional layer\n",
    "    with torch.no_grad():\n",
    "        conv_output = first_conv_layer(image.unsqueeze(0))  # Add batch dimension: (1, 1, H, W)\n",
    "        conv_output = conv_output.squeeze(0)  # Remove batch dimension: (32, H', W')\n",
    "\n",
    "    # Visualize the output of the first channel (i.e., the result of the first kernel)\n",
    "    first_kernel_output = conv_output[0].detach().cpu().numpy()  # Select the output corresponding to the first kernel\n",
    "    \n",
    "    plt.imshow(first_kernel_output, cmap='gray')\n",
    "    plt.title(\"Output of first kernel after first convolution\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "# Assuming the image is a single image tensor with shape (1, H, W), e.g., from train_dataloader\n",
    "# This assumes a grayscale image (1 channel), modify accordingly for RGB input\n",
    "\n",
    "# Load one image from the train set\n",
    "image, label = next(iter(train_dataloader))  # A batch from your dataloader\n",
    "single_image = image[0].to(device)  # Use the first image in the batch and send it to the correct device\n",
    "\n",
    "# Visualize the first kernel output\n",
    "visualize_first_kernel_output(model, single_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Sample Conv2D network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(64 * 28 * 28, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = ConvNet()\n",
    "\n",
    "# Store intermediate activations\n",
    "activations = {}\n",
    "\n",
    "# Define hook function\n",
    "def forward_hook(layer_name):\n",
    "    def hook(module, input, output):\n",
    "        activations[layer_name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks for all layers\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        layer.register_forward_hook(forward_hook(name))\n",
    "\n",
    "# Example input tensor (batch_size=1, channels=1, height=28, width=28)\n",
    "input_tensor = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Display the captured activations\n",
    "for layer_name, activation in activations.items():\n",
    "    print(f\"Layer: {layer_name}, Activation Shape: {activation.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def forward_checker(self, x):\n",
    "        print(x.size())\n",
    "\n",
    "        for layer in self.layers:\n",
    "            try:\n",
    "                x = layer(x)\n",
    "                print(f\"After {layer}: \",x.size())\n",
    "            except: #Do not use base exception!\n",
    "                print(\"Oops, that did not work!\", BaseException)\n",
    "                break\n",
    "\n",
    "class DiscountVGG:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "    def train():\n",
    "        pass\n",
    "\n",
    "\n",
    "class LightningVGG:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "model = CNN(None, None, 64, 10, in_channels = 3, lr=0.001)\n",
    "\n",
    "# summary(model, (3, 64, 64))\n",
    "\n",
    "model.forward_checker(torch.zeros(16, 3, 64, 64))\n",
    "\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)\n",
    "# None, None\n",
    "#         print(x.size())\n",
    "\n",
    "#         for layer in self.layers:\n",
    "#             try:\n",
    "#                 x = layer(x)\n",
    "#                 print(f\"After {layer}: \",x.size())\n",
    "#             except: #Do not use base exception!\n",
    "#                 print(\"Oops, that did not work!\", BaseException)\n",
    "#                 break\n",
    "\n",
    "# class DiscountVGG:\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         pass\n",
    "\n",
    "#     def train():\n",
    "#         pass\n",
    "\n",
    "\n",
    "# class LightningVGG:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty writer\n",
    "\n",
    "# TODO:\n",
    "# Make stdout catcher that works for ipynb (or at least has an option for it) and doesn't break stdout\n",
    "# Make a prettifier function that runs another function with the stdout capturer, captures the output\n",
    "# and then writes it using the prettifier code from gpt (formatting and all that) \n",
    "\n",
    "# Finally: Consider if you can't make prettywriter a wrapper rather than a context manager\n",
    "\n",
    "from io import StringIO\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def capture_stdout():\n",
    "    \"\"\"\n",
    "    context manager encapsulating a pattern for capturing stdout writes\n",
    "    and restoring sys.stdout even upon exceptions\n",
    "\n",
    "    Examples:\n",
    "    >>> with capture_stdout() as get_value:\n",
    "    >>>     print(\"here is a print\")\n",
    "    >>>     captured = get_value()\n",
    "    >>> print('Gotcha: ' + captured)\n",
    "\n",
    "    >>> with capture_stdout() as get_value:\n",
    "    >>>     print(\"here is a print\")\n",
    "    >>>     raise Exception('oh no!')\n",
    "    >>> print('Does printing still work?')\n",
    "    \"\"\"\n",
    "    # Redirect sys.stdout\n",
    "    out = StringIO()\n",
    "    sys.stdout = out\n",
    "    # Yield a method clients can use to obtain the value\n",
    "    try:\n",
    "        yield out.getvalue\n",
    "    finally:\n",
    "        # Restore the normal stdout\n",
    "        sys.stdout = sys.__stdout__\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout\n",
    "\n",
    "def parrot(num=5):\n",
    "    for i in range(num):\n",
    "        print(\"NUMBER:\", i)\n",
    "    \n",
    "with capture_stdout() as get_value:\n",
    "    print('here is a print')\n",
    "    parrot(10)\n",
    "    captured = get_value()\n",
    "print(\"GOTCHA\", captured)\n",
    "\n",
    "print(\"GOTCHA\")\n",
    "\n",
    "\n",
    "help_strings = [\n",
    "    (\"this is value 1\", 42),\n",
    "    (\"this is a longer text for value 2\", 3.14),\n",
    "    (\"another value\", 100),\n",
    "    (\"short\", 5)\n",
    "]\n",
    "\n",
    "# Find the maximum length of the help strings\n",
    "max_length = max(len(help) for help, _ in help_strings)\n",
    "\n",
    "# Print each help string with its value, aligned in columns\n",
    "for help, value in help_strings:\n",
    "    print(f\"{help:<{max_length}} : {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derp\n",
      "<ipykernel.iostream.OutStream object at 0x7383ec3b14e0>\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from ipykernel.iostream import OutStream\n",
    "nb_stdout = sys.stdout\n",
    "sys.stdout = nb_stdout\n",
    "print(\"derp\")\n",
    "print(nb_stdout)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size is: 16\n",
      "Input dim is (remember, there's also a color channel!): torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098\n"
     ]
    }
   ],
   "source": [
    "example_input, example_label = next(iter(train_dataloader))\n",
    "\n",
    "print(\"Batch size is:\", len(example_input))\n",
    "print(\"Input dim is (remember, there's also a color channel!):\", example_input.shape[1:])\n",
    "\n",
    "# TODO: Change both below to be not cancerous!\n",
    "in_features = example_input.flatten(start_dim=1).shape[-1]\n",
    "num_classes = 10 # \n",
    "\n",
    "model = FFN(None, None, in_features=in_features, num_classes=num_classes)\n",
    "\n",
    "model.train(train_dataloader, epochs=1)\n",
    "\n",
    "\n",
    "print(model.test(test_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW STOLEN FROM 02456 - DO NOT USE, OBVIOUSLY REWRITE IT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> EXE 1.1 </span> Manual calculations\n",
    "\n",
    "![](images/conv_exe.png)\n",
    "\n",
    "\n",
    "\n",
    "1. Manually convolve the input, and compute the convolved features. No padding and no strieds.\n",
    "1. Perform `2x2` max pooling on the convolved features. Stride of 2.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color:red\"> EXE 1.2 </span> Reducing the resolution\n",
    "One of the important features of convolutional networks are their ability to reduce the spatial resolution, while retaining the important features.\n",
    "Effectively this gives a local translational invariance and reduces the computation. \n",
    "This is most often done with **maxpooling** or by using strides.\n",
    "\n",
    "1. Using only convolutional layers and pooling operations reduce the feature map size to `1x1xF`.\n",
    "    * The number of feature maps, `F`, is up to you.\n",
    "\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Write down what you did: </span>\n",
    "\n",
    "``` \n",
    "Paste your code here\n",
    "```\n",
    "\n",
    "\n",
    "``` \n",
    "Paste the trace of the tensors shape as it is propagated through the network here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> EXE 1.3 </span> Play around with the network.\n",
    "The MNIST dataset is so easy to solve with convolutional networks that it isn't interesting to spend to much time on maximizing performance.\n",
    "A more interesting question is *how few parameters can you solve it with?*\n",
    "\n",
    "1. Try and minimize the number of parameters, while keeping validation accuracy about 95%. Try changing the\n",
    "\n",
    "    * Number of layers\n",
    "    * Number of filters\n",
    "    * Kernel size\n",
    "    * Pooling size\n",
    "1. Once happy take note of the performance, number of parameters (printed automatically), and describe the network below.\n",
    "___\n",
    "\n",
    "\n",
    "<span style=\"color:blue\"> Answer: </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> EXE 1.4 </span> Comparing dense and convolutional networks\n",
    "\n",
    "1. Now create a densely connected network (the ones from lab 1), and see how good performance you can get with a similar number of parameters.\n",
    "___\n",
    "\n",
    "<span style=\"color:blue\"> Describe your findings: </span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
